{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "\n",
    "1) Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from nltk) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\harod\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#libraries to be imported\n",
    "\n",
    "import os\n",
    "%pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "%pip install -qU langchain-text-splitters\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_text_splitters import NLTKTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#Importing pdf using langchain\n",
    "%pip install --upgrade --quiet pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.2.7-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from langchain_community) (6.0.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain_community)\n",
      "  Using cached SQLAlchemy-2.0.31-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain_community)\n",
      "  Using cached aiohttp-3.9.5-cp312-cp312-win_amd64.whl.metadata (7.7 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain<0.3.0,>=0.2.7 (from langchain_community)\n",
      "  Downloading langchain-0.2.8-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.12 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from langchain_community) (0.2.20)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from langchain_community) (0.1.88)\n",
      "Collecting numpy<2.0.0,>=1.26.0 (from langchain_community)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from langchain_community) (8.5.0)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached frozenlist-1.4.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached multidict-6.0.5-cp312-cp312-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached yarl-1.9.4-cp312-cp312-win_amd64.whl.metadata (32 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from langchain<0.3.0,>=0.2.7->langchain_community) (0.2.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from langchain<0.3.0,>=0.2.7->langchain_community) (2.8.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.12->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.12->langchain_community) (24.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.7.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.12.2)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain_community)\n",
      "  Using cached greenlet-3.0.3-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.12->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.7->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.7->langchain_community) (2.20.1)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain_community-0.2.7-py3-none-any.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/2.2 MB 2.2 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.3/2.2 MB 3.9 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.5/2.2 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.7/2.2 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.8/2.2 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.9/2.2 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.0/2.2 MB 3.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.1/2.2 MB 3.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.2/2.2 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.2/2.2 MB 2.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.4/2.2 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.4/2.2 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.5/2.2 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.7/2.2 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.8/2.2 MB 2.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.9/2.2 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.0/2.2 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.2/2.2 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 2.4 MB/s eta 0:00:00\n",
      "Using cached aiohttp-3.9.5-cp312-cp312-win_amd64.whl (369 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading langchain-0.2.8-py3-none-any.whl (987 kB)\n",
      "   ---------------------------------------- 0.0/987.6 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 143.4/987.6 kB 4.2 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 225.3/987.6 kB 2.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 491.5/987.6 kB 3.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 665.6/987.6 kB 3.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 829.4/987.6 kB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  983.0/987.6 kB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 987.6/987.6 kB 3.3 MB/s eta 0:00:00\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Using cached SQLAlchemy-2.0.31-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Using cached frozenlist-1.4.1-cp312-cp312-win_amd64.whl (50 kB)\n",
      "Using cached greenlet-3.0.3-cp312-cp312-win_amd64.whl (293 kB)\n",
      "Using cached marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
      "Using cached multidict-6.0.5-cp312-cp312-win_amd64.whl (27 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached yarl-1.9.4-cp312-cp312-win_amd64.whl (76 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: numpy, mypy-extensions, multidict, marshmallow, greenlet, frozenlist, attrs, yarl, typing-inspect, SQLAlchemy, aiosignal, dataclasses-json, aiohttp, langchain, langchain_community\n",
      "Successfully installed SQLAlchemy-2.0.31 aiohttp-3.9.5 aiosignal-1.3.1 attrs-23.2.0 dataclasses-json-0.6.7 frozenlist-1.4.1 greenlet-3.0.3 langchain-0.2.8 langchain_community-0.2.7 marshmallow-3.21.3 multidict-6.0.5 mypy-extensions-1.0.0 numpy-1.26.4 typing-inspect-0.9.0 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\A'\n",
      "C:\\Users\\harod\\AppData\\Local\\Temp\\ipykernel_13192\\2358556032.py:4: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  \"C:\\All_projects\\Question_Answering_System\\Caterpillar Tunneling Revitalizing User Adoption of Business Intelligence.pdf\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = (\n",
    "    \"C:\\All_projects\\Question_Answering_System\\Caterpillar Tunneling Revitalizing User Adoption of Business Intelligence.pdf\"\n",
    ")\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'C:\\\\All_projects\\\\Question_Answering_System\\\\Caterpillar Tunneling Revitalizing User Adoption of Business Intelligence.pdf', 'page': 0}, page_content='W13513   \\n \\n \\nCATERPILLAR TUNNELING: REVI TALIZING USER ADOPTION OF \\nBUSINESS INTELLIGENCE \\n \\n \\nFrances Leung and Murat Kristal wrote this case solely to provide material for class discussion. The authors do not intend to \\nillustrate either effective or ineffective handling of a manager ial situation. The authors may have disguised certain names and  other \\nidentifying information to protect confidentiality. \\n This publication may not be transmitted, photoc opied, digitized or otherwise reproduced in any form or by any means without the  \\npermission of the copyright holder. Reproducti on of this material is not covered under  authorization by any reproduction rights  \\norganization. To order copies or request per mission to reproduce materials, contact Iv ey Publishing, Ivey Business School, West ern \\nUniversity, London, Ontario, Canada, N6G 0N1; (t) 519.661.3208; (e) cases@ivey.ca; www.iveycases.com. \\n Copyright © 2013, Richard Ivey School of Business Foundation Version: 2014-03-31 \\n \\n \\nCaterpillar Tunneling Canada Corpora tion (CTCC), a subsidiary of the U.S. company Caterpillar Inc., had \\nbeen experiencing a host of problems — e.g., data  inconsistency, uneven re porting and poorly defined \\nprocesses — with its outdated enterprise resour ce planning (ERP) system. Between 2011 and 2012, it \\nplanned to upgrade to its parent company’s SAP but  had to cancel due to resource allocation issues. A \\nbusiness intelligence (BI) platform had been deployed locally as an intermediary solution to facilitate \\nbusiness decision making; after the cancellation, it became  an even more critical tool to complement the \\ntroubled ERP system in transforming raw and dispar ate business data into actionable business insights. \\nFaced with limited information technology (IT) resources,  an inflexible ERP infrastructure, imbalanced \\nuser adoption of BI, and under pressure to generate  timely financial and performance reporting to the \\ncorporate office, Jon McEwan, the CTCC’s business resource manager and head of the finance \\ndepartment, struggled to turn the existing BI solution into the platform of choice for trusted information distribution throughout the company.  \\n \\nThe BI platform allowed users to link disparate data sources successfully, but not all business units within \\nthe company were ready to adopt the software. As a result, the different levels of participation, technical \\naptitude and personal motivation created an imbalan ced reporting landscape characterized by two types of \\nusers. On one hand, the analytics junkies who favoured slicing and dicing interactive datasets on their own and getting hands-on with the late st data visualization utilities. On the other, the canned report users \\nwho were passive in performing their own analyses or  looking beyond the static results generated, and \\npreferred receiving information from the traditional cha nnels with which they were most familiar. Thus, \\nthe BI platform had become both the go-to platform for effective decision making for some and a source \\nof multiple versions of the truth for others.  \\n \\nThis great divide fostered the emergence of “information insiders” who were more proficient in extracting business insights for decision making than those who were less technology-savvy or less adaptive to new tools and processes. To release the full potential of th e existing BI platform, McEwan had to focus his \\nenergy on user needs and the flaws of the initial BI platform implementation.  \\n \\n \\nThis document is authorized for use only in Prof Kalpit Sharma©s MSDSM01_Computer and Information Systems at Indian Institute of Management - Amritsar from Dec 2023 to Jun 2024.')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_10= pages[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'C:\\\\All_projects\\\\Question_Answering_System\\\\Caterpillar Tunneling Revitalizing User Adoption of Business Intelligence.pdf', 'page': 1}, page_content='2013.  \\n3 Kim Laudrum, “Lovat Has Tunnel Vision,”  Plant, February 18, 2008: pp. 17—19.  \\nThis document is authorized for use only in Prof Kalpit Sharma©s MSDSM01_Computer and Information Systems at Indian Institute of Management - Amritsar from Dec 2023 to Jun 2024.')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_10[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(first_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_text = ''.join(page.page_content for page in first_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(combined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 878, which is longer than the specified 650\n"
     ]
    }
   ],
   "source": [
    "#use nltk to split the pages document to chunks of size 100\n",
    "first_10= pages[:7]\n",
    "\n",
    "text_splitter = NLTKTextSplitter(chunk_size=650,chunk_overlap=0)\n",
    "texts = text_splitter.split_text(combined_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This splits by 100 tokens approx and maintains sentance boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['W13513   \\n \\n \\nCATERPILLAR TUNNELING: REVI TALIZING USER ADOPTION OF \\nBUSINESS INTELLIGENCE \\n \\n \\nFrances Leung and Murat Kristal wrote this case solely to provide material for class discussion.\\n\\nThe authors do not intend to \\nillustrate either effective or ineffective handling of a manager ial situation.\\n\\nThe authors may have disguised certain names and  other \\nidentifying information to protect confidentiality.\\n\\nThis publication may not be transmitted, photoc opied, digitized or otherwise reproduced in any form or by any means without the  \\npermission of the copyright holder.',\n",
       " 'Reproducti on of this material is not covered under  authorization by any reproduction rights  \\norganization.\\n\\nTo order copies or request per mission to reproduce materials, contact Iv ey Publishing, Ivey Business School, West ern \\nUniversity, London, Ontario, Canada, N6G 0N1; (t) 519.661.3208; (e) cases@ivey.ca; www.iveycases.com.',\n",
       " 'Copyright © 2013, Richard Ivey School of Business Foundation Version: 2014-03-31 \\n \\n \\nCaterpillar Tunneling Canada Corpora tion (CTCC), a subsidiary of the U.S. company Caterpillar Inc., had \\nbeen experiencing a host of problems — e.g., data  inconsistency, uneven re porting and poorly defined \\nprocesses — with its outdated enterprise resour ce planning (ERP) system.\\n\\nBetween 2011 and 2012, it \\nplanned to upgrade to its parent company’s SAP but  had to cancel due to resource allocation issues.',\n",
       " 'A \\nbusiness intelligence (BI) platform had been deployed locally as an intermediary solution to facilitate \\nbusiness decision making; after the cancellation, it became  an even more critical tool to complement the \\ntroubled ERP system in transforming raw and dispar ate business data into actionable business insights.',\n",
       " 'Faced with limited information technology (IT) resources,  an inflexible ERP infrastructure, imbalanced \\nuser adoption of BI, and under pressure to generate  timely financial and performance reporting to the \\ncorporate office, Jon McEwan, the CTCC’s business resource manager and head of the finance \\ndepartment, struggled to turn the existing BI solution into the platform of choice for trusted information distribution throughout the company.\\n\\nThe BI platform allowed users to link disparate data sources successfully, but not all business units within \\nthe company were ready to adopt the software.',\n",
       " 'As a result, the different levels of participation, technical \\naptitude and personal motivation created an imbalan ced reporting landscape characterized by two types of \\nusers.\\n\\nOn one hand, the analytics junkies who favoured slicing and dicing interactive datasets on their own and getting hands-on with the late st data visualization utilities.\\n\\nOn the other, the canned report users \\nwho were passive in performing their own analyses or  looking beyond the static results generated, and \\npreferred receiving information from the traditional cha nnels with which they were most familiar.',\n",
       " 'Thus, \\nthe BI platform had become both the go-to platform for effective decision making for some and a source \\nof multiple versions of the truth for others.\\n\\nThis great divide fostered the emergence of “information insiders” who were more proficient in extracting business insights for decision making than those who were less technology-savvy or less adaptive to new tools and processes.\\n\\nTo release the full potential of th e existing BI platform, McEwan had to focus his \\nenergy on user needs and the flaws of the initial BI platform implementation.',\n",
       " 'This document is authorized for use only in Prof Kalpit Sharma©s MSDSM01_Computer and Information Systems at Indian Institute of Management - Amritsar from Dec 2023 to Jun 2024.Page 2 9B13E030  \\n \\n \\n SAP BUSINESS TRANSFORMA TION AT CATERPILLAR \\n \\nFrom 2005 to 2006, Caterpillar emba rked on a business transformation project to implement SAP across \\nits machine and engine businesses to replace a host of legacy systems and to standardize an enterprise-\\nwide ERP platform.1 To facilitate the transformation, Caterp illar established a special taskforce called \\nMACH 1 that would work with new target deployment  sites to localize the Caterpillar SAP template to \\nthe site’s business and legal requirements, support transformation to the enterprise business processes, map and load legacy system data into SAP, participate in system user acceptance testing and train local users.',\n",
       " '2  \\n \\nIn 2010, CTCC was selected as one of the sites to  undergo SAP implementation.\\n\\nA team of key \\nemployees was selected to act as subject matter experts and collaborate with the corporate team and external consultants to assess CTCC’s business processes and determine the gaps that the corporate SAP \\ntemplate would need to overcome.\\n\\nAfter more than a year of localization sessions and data cleansing efforts by the local, corporate and external teams, th e project was put on hold indefinitely, mostly because \\nthe implementation was demanding more local resources from CTCC than previously expected.',\n",
       " 'The \\ndiscontinuation of the project allowed corporate res ources to be offloaded to other sites with higher \\npriorities for SAP transformation.\\n\\nFurthermore, the ga p analysis revealed that CTCC’s unique concurrent \\nengineering and project-based business model would re quire a SAP template to be designed from scratch \\nto facilitate the management of the end-to-end cy cle from design to delivery for tunnel boring machine \\n(TBM) projects, an endeavour unfamiliar to the cor porate and external teams.\\n\\nCTCC was left with no \\nchoice but to operate under its original ERP system with  no plan to invest further in ERP development.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Vector embedding using models from SBERT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformersNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers<5.0.0,>=4.34.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.42.4-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 43.6/43.6 kB 2.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from sentence-transformers) (4.66.4)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.3.1-cp312-cp312-win_amd64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: numpy in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from sentence-transformers) (1.26.4)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Using cached scikit_learn-1.5.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.14.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting huggingface-hub>=0.15.1 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.23.5-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Using cached pillow-10.4.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.15.1->sentence-transformers)\n",
      "  Using cached filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.15.1->sentence-transformers)\n",
      "  Using cached fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n",
      "Collecting sympy (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading sympy-1.13.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: colorama in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.34.0->sentence-transformers)\n",
      "  Using cached safetensors-0.4.3-cp312-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers<5.0.0,>=4.34.0->sentence-transformers)\n",
      "  Using cached tokenizers-0.19.1-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting intel-openmp==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers)\n",
      "  Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting tbb==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers)\n",
      "  Downloading tbb-2021.13.0-py3-none-win_amd64.whl.metadata (1.1 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers)\n",
      "  Using cached MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.7.4)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch>=1.11.0->sentence-transformers)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
      "   ---------------------------------------- 0.0/227.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 227.1/227.1 kB 7.0 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.23.5-py3-none-any.whl (402 kB)\n",
      "   ---------------------------------------- 0.0/402.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 402.8/402.8 kB 26.2 MB/s eta 0:00:00\n",
      "Downloading torch-2.3.1-cp312-cp312-win_amd64.whl (159.7 MB)\n",
      "   ---------------------------------------- 0.0/159.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.1/159.7 MB 34.4 MB/s eta 0:00:05\n",
      "    --------------------------------------- 2.9/159.7 MB 31.2 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 4.2/159.7 MB 38.0 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 5.4/159.7 MB 34.5 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 7.5/159.7 MB 36.7 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 9.1/159.7 MB 36.3 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 11.5/159.7 MB 40.9 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 13.9/159.7 MB 43.7 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 16.1/159.7 MB 46.7 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 17.2/159.7 MB 46.9 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 19.1/159.7 MB 43.7 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 20.9/159.7 MB 43.7 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 22.8/159.7 MB 43.7 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 24.9/159.7 MB 40.9 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 25.8/159.7 MB 43.5 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 27.0/159.7 MB 34.4 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 28.8/159.7 MB 38.5 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 30.4/159.7 MB 36.4 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 32.7/159.7 MB 38.5 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 34.3/159.7 MB 36.3 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 35.9/159.7 MB 36.4 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 37.7/159.7 MB 38.6 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 39.4/159.7 MB 40.9 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 40.3/159.7 MB 38.5 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 41.6/159.7 MB 36.3 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 42.3/159.7 MB 32.7 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 43.1/159.7 MB 29.8 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 44.3/159.7 MB 29.8 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 45.4/159.7 MB 27.3 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 46.1/159.7 MB 25.2 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 46.7/159.7 MB 24.2 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 47.3/159.7 MB 22.6 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 47.9/159.7 MB 21.8 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 48.4/159.7 MB 19.8 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 48.9/159.7 MB 19.3 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 49.4/159.7 MB 18.7 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 50.1/159.7 MB 17.2 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 50.7/159.7 MB 16.8 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 51.4/159.7 MB 16.8 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 52.1/159.7 MB 15.6 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 52.7/159.7 MB 16.4 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 53.2/159.7 MB 15.6 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 53.8/159.7 MB 15.2 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 54.5/159.7 MB 14.9 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 55.0/159.7 MB 14.6 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 55.8/159.7 MB 13.9 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 56.5/159.7 MB 13.9 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 57.1/159.7 MB 13.9 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 57.8/159.7 MB 13.9 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 58.5/159.7 MB 14.2 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 59.3/159.7 MB 14.6 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 59.8/159.7 MB 14.6 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 60.7/159.7 MB 14.9 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 61.4/159.7 MB 14.9 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 62.2/159.7 MB 15.2 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 62.9/159.7 MB 14.9 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 63.6/159.7 MB 15.6 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 64.5/159.7 MB 16.0 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 65.3/159.7 MB 16.4 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 66.1/159.7 MB 16.4 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 66.7/159.7 MB 16.4 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 67.7/159.7 MB 16.8 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 68.3/159.7 MB 16.8 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 69.2/159.7 MB 17.2 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 70.0/159.7 MB 17.2 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 70.7/159.7 MB 17.2 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 71.5/159.7 MB 17.2 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 72.3/159.7 MB 17.2 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 73.2/159.7 MB 18.2 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 74.2/159.7 MB 18.2 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 75.0/159.7 MB 18.7 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 75.9/159.7 MB 18.7 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 76.7/159.7 MB 18.7 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 77.6/159.7 MB 18.7 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 78.4/159.7 MB 18.7 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 79.4/159.7 MB 18.7 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 80.2/159.7 MB 19.9 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 81.2/159.7 MB 19.8 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 82.2/159.7 MB 19.8 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 83.0/159.7 MB 19.8 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 83.9/159.7 MB 20.5 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 84.7/159.7 MB 20.5 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 85.6/159.7 MB 20.5 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 86.5/159.7 MB 20.5 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 87.2/159.7 MB 20.5 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 88.3/159.7 MB 21.1 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 89.0/159.7 MB 21.1 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 90.1/159.7 MB 21.1 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 91.1/159.7 MB 21.8 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 92.3/159.7 MB 21.1 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 93.2/159.7 MB 21.8 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 94.2/159.7 MB 21.9 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 95.2/159.7 MB 22.6 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 96.1/159.7 MB 22.5 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 97.1/159.7 MB 22.6 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 97.6/159.7 MB 21.8 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 98.5/159.7 MB 21.8 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 99.5/159.7 MB 21.9 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 100.5/159.7 MB 21.1 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 101.5/159.7 MB 22.5 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 102.5/159.7 MB 21.9 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 103.5/159.7 MB 22.6 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 104.5/159.7 MB 22.5 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 105.4/159.7 MB 21.9 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 106.4/159.7 MB 22.6 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 107.4/159.7 MB 22.5 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 108.5/159.7 MB 23.4 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 109.5/159.7 MB 24.2 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 110.3/159.7 MB 24.2 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 111.6/159.7 MB 25.2 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 112.6/159.7 MB 24.2 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 113.9/159.7 MB 25.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 115.0/159.7 MB 25.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 116.2/159.7 MB 25.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 117.4/159.7 MB 25.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 118.3/159.7 MB 25.2 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 119.6/159.7 MB 26.2 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 120.3/159.7 MB 26.2 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 121.1/159.7 MB 24.2 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 122.0/159.7 MB 23.4 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 123.0/159.7 MB 23.4 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 123.8/159.7 MB 22.6 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 124.5/159.7 MB 22.6 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 125.5/159.7 MB 22.6 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 126.2/159.7 MB 21.1 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 127.3/159.7 MB 21.1 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 128.3/159.7 MB 20.5 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 129.1/159.7 MB 19.9 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 130.2/159.7 MB 19.9 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 131.0/159.7 MB 19.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 131.9/159.7 MB 20.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 132.6/159.7 MB 19.9 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 133.8/159.7 MB 20.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 134.7/159.7 MB 19.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 136.0/159.7 MB 20.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 136.8/159.7 MB 21.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 137.8/159.7 MB 21.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 138.6/159.7 MB 21.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 139.6/159.7 MB 21.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 140.5/159.7 MB 21.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 141.1/159.7 MB 21.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 141.9/159.7 MB 21.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 142.6/159.7 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 143.2/159.7 MB 20.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 143.9/159.7 MB 19.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 144.4/159.7 MB 19.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 145.2/159.7 MB 19.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 145.9/159.7 MB 18.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 146.8/159.7 MB 18.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 147.4/159.7 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 148.2/159.7 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 148.9/159.7 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 149.5/159.7 MB 17.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 150.3/159.7 MB 16.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 151.0/159.7 MB 17.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 151.7/159.7 MB 16.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 152.5/159.7 MB 16.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 153.1/159.7 MB 17.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 154.1/159.7 MB 17.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 154.8/159.7 MB 17.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 155.5/159.7 MB 17.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  156.3/159.7 MB 18.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  157.1/159.7 MB 18.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  157.9/159.7 MB 18.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  158.8/159.7 MB 18.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.5/159.7 MB 18.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 18.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 159.7/159.7 MB 9.5 MB/s eta 0:00:00\n",
      "Downloading transformers-4.42.4-py3-none-any.whl (9.3 MB)\n",
      "   ---------------------------------------- 0.0/9.3 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.9/9.3 MB 19.4 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 1.8/9.3 MB 22.4 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 2.8/9.3 MB 22.0 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.6/9.3 MB 21.0 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.4/9.3 MB 20.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.3/9.3 MB 21.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.2/9.3 MB 20.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 6.6/9.3 MB 20.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.0/9.3 MB 21.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.8/9.3 MB 20.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.3/9.3 MB 20.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.3/9.3 MB 18.7 MB/s eta 0:00:00\n",
      "Using cached pillow-10.4.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "Using cached scikit_learn-1.5.1-cp312-cp312-win_amd64.whl (10.9 MB)\n",
      "Using cached scipy-1.14.0-cp312-cp312-win_amd64.whl (44.5 MB)\n",
      "Using cached fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl (228.5 MB)\n",
      "Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl (3.5 MB)\n",
      "Downloading tbb-2021.13.0-py3-none-win_amd64.whl (286 kB)\n",
      "   ---------------------------------------- 0.0/286.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 286.9/286.9 kB 5.9 MB/s eta 0:00:00\n",
      "Using cached safetensors-0.4.3-cp312-none-win_amd64.whl (289 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached tokenizers-0.19.1-cp312-none-win_amd64.whl (2.2 MB)\n",
      "Using cached filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Downloading sympy-1.13.0-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.8/6.2 MB 27.1 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 1.8/6.2 MB 23.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 2.8/6.2 MB 22.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.8/6.2 MB 22.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.8/6.2 MB 21.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.6/6.2 MB 22.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.2/6.2 MB 22.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 19.8 MB/s eta 0:00:00\n",
      "Using cached MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl (17 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: tbb, mpmath, intel-openmp, threadpoolctl, sympy, scipy, safetensors, Pillow, networkx, mkl, MarkupSafe, fsspec, filelock, scikit-learn, jinja2, huggingface-hub, torch, tokenizers, transformers, sentence-transformers\n",
      "Successfully installed MarkupSafe-2.1.5 Pillow-10.4.0 filelock-3.15.4 fsspec-2024.6.1 huggingface-hub-0.23.5 intel-openmp-2021.4.0 jinja2-3.1.4 mkl-2021.4.0 mpmath-1.3.0 networkx-3.3 safetensors-0.4.3 scikit-learn-1.5.1 scipy-1.14.0 sentence-transformers-3.0.1 sympy-1.13.0 tbb-2021.13.0 threadpoolctl-3.5.0 tokenizers-0.19.1 torch-2.3.1 transformers-4.42.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -U sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\All_projects\\Question_Answering_System\\qaenv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nmodel = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')    #Change the mdoel according to the research ppr\\nembeddings = model.encode(texts)\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "'''\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')    #Change the mdoel according to the research ppr\n",
    "embeddings = model.encode(texts)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing RAPTOR indexing method\n",
    "- To capture both higher and lower level information\n",
    "- Long context results in loss of information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.2.2-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Using cached pandas-2.2.2-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.2 pytz-2024.1 tzdata-2024.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '–'\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install –upgrade umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_groq\n",
      "  Downloading langchain_groq-0.1.6-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
      "  Using cached groq-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2.2 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from langchain_groq) (0.2.20)\n",
      "Collecting anyio<5,>=3.5.0 (from groq<1,>=0.4.1->langchain_groq)\n",
      "  Using cached anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from groq<1,>=0.4.1->langchain_groq)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from groq<1,>=0.4.1->langchain_groq)\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (2.8.2)\n",
      "Collecting sniffio (from groq<1,>=0.4.1->langchain_groq)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (4.12.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from langchain-core<0.3,>=0.2.2->langchain_groq) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from langchain-core<0.3,>=0.2.2->langchain_groq) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from langchain-core<0.3,>=0.2.2->langchain_groq) (0.1.88)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from langchain-core<0.3,>=0.2.2->langchain_groq) (24.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from langchain-core<0.3,>=0.2.2->langchain_groq) (8.5.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (2024.7.4)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq)\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.2->langchain_groq) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.2->langchain_groq) (3.10.6)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.2->langchain_groq) (2.32.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.2->langchain_groq) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.2->langchain_groq) (2.2.2)\n",
      "Downloading langchain_groq-0.1.6-py3-none-any.whl (14 kB)\n",
      "Using cached groq-0.9.0-py3-none-any.whl (103 kB)\n",
      "Using cached anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: sniffio, h11, distro, httpcore, anyio, httpx, groq, langchain_groq\n",
      "Successfully installed anyio-4.4.0 distro-1.9.0 groq-0.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 langchain_groq-0.1.6 sniffio-1.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_API_KEY=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_llm= ChatGroq(groq_api_key=GROQ_API_KEY,\n",
    "              model_name='llama3-70b-8192')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the global clustering function\n",
    "\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "import umap\n",
    "\n",
    "RANDOM_SEED=42\n",
    "\n",
    "def global_cluster_embeddings(\n",
    "        embeddings:np.ndarray,\n",
    "        dim: int,\n",
    "        n_neighbors: Optional[int] = None,\n",
    "        metric:str = \"cosine\",\n",
    "\n",
    ") -> np.ndarray:\n",
    "    \n",
    "    \"\"\"perform global dimensionality reduction on the embeddings using UMAP.\n",
    "    \n",
    "    parameters:\n",
    "    - embedding: The input embeddings as a numpy array.\n",
    "    - dim: The target dimensionality for the reduced space.\n",
    "    - n_neighbors: Optional; the number of neighbors to consider for each point.\n",
    "                   If not provided, it defaults to the square root of the number of embeddings.\n",
    "    - metric: The distance metric to use for UMAP \n",
    "    \n",
    "    Returns: A numpy array of the embeddings reduced to the specified dimensionality\"\"\"\n",
    "\n",
    "    if n_neighbors is None:\n",
    "        n_neighbors= int((len(embeddings)-1)** 0.5)\n",
    "    return umap.UMAP(\n",
    "        n_neighbors=n_neighbors, n_components=dim, metric=metric \n",
    "    ).fit_transform(embeddings)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Local clustering\n",
    "\n",
    "def local_cluster_embeddings(\n",
    "        embeddings: np.ndarray, dim:int, num_neighbors:int=10, metric:str=\"cosine\"\n",
    ")-> np.ndarray:\n",
    "    \"\"\"\"Docs  \"\"\"\n",
    "\n",
    "    return umap.UMAP(\n",
    "        n_neighbors=num_neighbors, n_components=dim,metric=metric\n",
    "    ).fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get optimal number of of clusters\n",
    "\n",
    "\n",
    "def get_optimal_clusters(\n",
    "        embeddings: np.ndarray, max_clusters: int = 50, random_state: int= RANDOM_SEED\n",
    ") -> int:\n",
    "    \n",
    "    max_clusters=min(max_clusters,len(embeddings))\n",
    "    n_clusters= np.arange(1, max_clusters)\n",
    "    bics=[]\n",
    "    \n",
    "    for n in n_clusters:\n",
    "        gm= GaussianMixture(n_components=n,random_state=random_state)\n",
    "        gm.fit(embeddings)\n",
    "        bics.append(gm.bic(embeddings))\n",
    "    return n_clusters[np.argmin(bics)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to perform cluster embeddibg using a GMM\n",
    "\n",
    "def GMM_cluster(embeddings: np.ndarray, threshold: float, random_state:int=0):\n",
    "\n",
    "    \"\"\"DOCS\"\"\"\n",
    "\n",
    "    n_clusters= get_optimal_clusters(embeddings)\n",
    "    gm= GaussianMixture(n_components=n_clusters, random_state=random_state)\n",
    "    gm.fit(embeddings)\n",
    "    probs = gm.predict_proba(embeddings)\n",
    "    labels = [np.where(prob>threshold)[0] for prob in probs]\n",
    "    return labels, n_clusters\n",
    "\n",
    "def perform_clustering(embeddings:np.ndarray, dim: int, threshold: float)-> List[np.ndarray]:\n",
    "    \"\"\"DOCS\"\"\"\n",
    "\n",
    "    if len(embeddings) <= dim+1:\n",
    "        #avoid clustering when theres insufficient data\n",
    "        return [np.array([0]) for _ in range(len(embeddings))]\n",
    "    # Global dimensionality reduction\n",
    "\n",
    "    reduced_embeddings_global= global_cluster_embeddings(embeddings, dim)\n",
    "\n",
    "    #Global clustering\n",
    "\n",
    "    global_clusters, n_global_clusters =GMM_cluster(\n",
    "        reduced_embeddings_global,threshold\n",
    "    )\n",
    "\n",
    "    all_local_clusters = [np.array([]) for _ in range(len(embeddings))]\n",
    "    total_clusters = 0\n",
    "\n",
    "    #Iterate through each global cluster to perform local clustering\n",
    "\n",
    "    for i in range(n_global_clusters):\n",
    "        #Extract embeddings belonging to the current global cluster\n",
    "\n",
    "        global_cluster_embeddings_= embeddings[\n",
    "            np.array([i in gc for gc in global_clusters])\n",
    "        ]\n",
    "\n",
    "        if len(global_cluster_embeddings_) == 0:\n",
    "            continue\n",
    "        if len(global_cluster_embeddings_)<= dim +1:\n",
    "            #handle small clusters with direct assignmemt\n",
    "            local_clusters= [np.array([0]) for _ in global_cluster_embeddings_]\n",
    "            n_local_clusters=1\n",
    "        else:\n",
    "            #Local dimensiioanlity reduction and clustering\n",
    "            reduced_embeddings_local= local_cluster_embeddings(\n",
    "                global_cluster_embeddings_,dim\n",
    "            )\n",
    "            local_clusters, n_local_clusters = GMM_cluster(\n",
    "                reduced_embeddings_local,threshold\n",
    "            )\n",
    "\n",
    "        # Assign local cluster IDs, adjusting for total clusters already processed\n",
    "\n",
    "        for j in range(n_local_clusters):\n",
    "            local_cluster_embeddings_ = global_cluster_embeddings_[\n",
    "                np.array([j in lc for lc in local_clusters])\n",
    "            ]\n",
    "            indices = np.where(\n",
    "                (embeddings == local_cluster_embeddings_[:, None]).all(-1)\n",
    "            )[1]\n",
    "            for idx in indices:\n",
    "                all_local_clusters[idx] = np.append(\n",
    "                    all_local_clusters[idx], j + total_clusters\n",
    "                )\n",
    "\n",
    "        total_clusters += n_local_clusters\n",
    "\n",
    "    return all_local_clusters\n",
    "\n",
    "\n",
    "     \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embedding text docs\n",
    "\n",
    "def embed_text(docs):\n",
    "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    embeddings = model.encode(docs)\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def  cluster_embed_text(texts):\n",
    "    \"\"\"DOCS\"\"\"\n",
    "\n",
    "    text_embedding= embed_text(texts)\n",
    "    cluster_labels= perform_clustering(\n",
    "        text_embedding,10,0.1\n",
    "    )\n",
    "    df_store=pd.DataFrame() # to store the results\n",
    "    df_store[\"text\"]=texts\n",
    "    \n",
    "    \n",
    "    df_store[\"embd\"]= list(text_embedding)\n",
    "    df_store[\"cluster\"]= cluster_labels \n",
    "    return df_store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt_txt(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Formats the text documents in a DataFrame into a single string.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the 'text' column with text documents to format.\n",
    "\n",
    "    Returns:\n",
    "    - A single string where all text documents are joined by a specific delimiter.\n",
    "    \"\"\"\n",
    "    unique_txt = df[\"text\"].tolist()\n",
    "    return \"--- --- \\n --- --- \".join(unique_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_cluster_summarize(\n",
    "        texts:List[str], level:int\n",
    ")-> Tuple[pd.DataFrame,pd.DataFrame]:\n",
    "    \"\"\"DOCS\"\"\"\n",
    "\n",
    "    df_clusters = cluster_embed_text(texts)\n",
    "\n",
    "    expanded_list= []\n",
    "\n",
    "    # Expand DataFrame entries to document-cluster pairings for straightforward processing\n",
    "    for index, row in df_clusters.iterrows():\n",
    "        for cluster in row[\"cluster\"]:\n",
    "            expanded_list.append(\n",
    "                {\"text\": row[\"text\"], \"embd\": row[\"embd\"], \"cluster\": cluster}\n",
    "            )\n",
    "    # Create a new DataFrame from the expanded list\n",
    "    expanded_df = pd.DataFrame(expanded_list)\n",
    "\n",
    "    # Retrieve unique cluster identifiers for processing\n",
    "    all_clusters = expanded_df[\"cluster\"].unique()\n",
    "\n",
    "    print(f\"--Generated {len(all_clusters)} clusters--\")\n",
    "\n",
    "\n",
    "        # Summarization\n",
    "    template = \"\"\"Here is a document on Caterpillar.\n",
    "\n",
    "    Give a detailed summary of the documentation provided.Avoid any such phrases \"Here is a detailed summary of the document provided:\".Just provide the detailed summary\n",
    "\n",
    "    Documentation:\n",
    "    {context}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    chain = prompt | model | StrOutputParser()     #where is model and stroutputparser?\n",
    "    \n",
    "    # Format text within each cluster for summarization\n",
    "    summaries = []\n",
    "    for i in all_clusters:\n",
    "        df_cluster = expanded_df[expanded_df[\"cluster\"] == i]\n",
    "        formatted_txt = fmt_txt(df_cluster)\n",
    "        summaries.append(chain.invoke({\"context\": formatted_txt}))\n",
    "\n",
    "# Create a DataFrame to store summaries with their corresponding cluster and level\n",
    "    df_summary = pd.DataFrame(\n",
    "            {\n",
    "                \"summaries\": summaries,\n",
    "                \"level\": [level] * len(summaries),\n",
    "                \"cluster\": list(all_clusters),\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    return df_clusters, df_summary\n",
    "\n",
    "def recursive_embed_cluster_summarize(\n",
    "    texts: List[str], level: int = 1, n_levels: int = 3  #form 3 to 4\n",
    ") -> Dict[int, Tuple[pd.DataFrame, pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    Recursively embeds, clusters, and summarizes texts up to a specified level or until\n",
    "    the number of unique clusters becomes 1, storing the results at each level.\n",
    "\n",
    "    Parameters:\n",
    "    - texts: List[str], texts to be processed.\n",
    "    - level: int, current recursion level (starts at 1).\n",
    "    - n_levels: int, maximum depth of recursion.\n",
    "\n",
    "    Returns:\n",
    "    - Dict[int, Tuple[pd.DataFrame, pd.DataFrame]], a dictionary where keys are the recursion\n",
    "      levels and values are tuples containing the clusters DataFrame and summaries DataFrame at that level.\n",
    "    \"\"\"\n",
    "    results = {}  # Dictionary to store results at each level\n",
    "\n",
    "    # Perform embedding, clustering, and summarization for the current level\n",
    "    df_clusters, df_summary = embed_cluster_summarize(texts, level)\n",
    "\n",
    "    # Store the results of the current level\n",
    "    results[level] = (df_clusters, df_summary)\n",
    "\n",
    "    # Determine if further recursion is possible and meaningful\n",
    "    unique_clusters = df_summary[\"cluster\"].nunique()\n",
    "    \n",
    "    if level < n_levels and unique_clusters > 1:\n",
    "        # Use summaries as the input texts for the next level of recursion\n",
    "        new_texts = df_summary[\"summaries\"].tolist()\n",
    "        next_level_results = recursive_embed_cluster_summarize(\n",
    "            new_texts, level + 1, n_levels\n",
    "        )\n",
    "        # Merge the results from the next level into the current results dictionary\n",
    "        results.update(next_level_results)\n",
    "        \n",
    "    if level == n_levels or unique_clusters == 1:\n",
    "        print(\"this is executed\")\n",
    "\n",
    "        f_summary= df_summary[\"summaries\"].tolist()\n",
    "        f_embed=embed_text(f_summary)\n",
    "        print(f_summary)\n",
    "        df_final_embeddings = pd.DataFrame(\n",
    "            {\n",
    "                \"text\": f_summary,\n",
    "                \"embd\": list(f_embed),\n",
    "                \"cluster\": df_summary[\"cluster\"],\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Append the final summaries embeddings to df_clusters\n",
    "        df_clusters = pd.concat([df_clusters, df_final_embeddings])\n",
    "        print(\"done\")\n",
    "        print(df_clusters)\n",
    "        results[level]=(df_clusters,df_summary)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Generated 7 clusters--\n",
      "--Generated 1 clusters--\n",
      "this is executed\n",
      "[\"Here is a detailed summary of the document:\\n\\nCaterpillar, a multinational corporation, acquired Lovat Inc., a tunnel boring company, in 2008. However, the integration of Lovat into Caterpillar's organization was challenging due to Lovat's lack of organizational governance and structure. Lovat, renamed Caterpillar Tunneling Canada Corporation (CTCC), operated in a reactive manner with many activities carried out without formal processes, and decision-making was often dominated by undocumented tribal knowledge.\\n\\nThe IT department at CTCC faced numerous issues, including an outdated enterprise resource planning (ERP) system, which was eventually cancelled due to resource allocation issues. The company was left with an old ERP system with no plans for further development. However, the need to streamline and standardize processes grew as CTCC integrated more closely with its parent company.\\n\\nTo address these issues, Caterpillar's business intelligence (BI) platform was deployed as an intermediate solution to facilitate business decision making. However, the platform faced challenges due to limited IT resources, an inflexible ERP infrastructure, and imbalanced user adoption.\\n\\nCTCC, a leading provider of tunneling technologies, specializes in the custom design and manufacture of tunnel boring machines (TBMs) for soft ground to hard rock geological conditions. The company has contributed to various infrastructure projects globally, including transportation and utility tunnels, sewers, and underground cables.\\n\\nThe company's quality assurance (QA) system had basic functionalities but lacked reporting functionalities. The QA system was later reorganized and became part of Caterpillar's Global Information Services (GIS) unit, with expanded responsibilities to support multiple Caterpillar facilities outside of Toronto.\\n\\nThe implementation of a proprietary web update system and the evolution of Caterpillar's business systems landscape also played a significant role in addressing the company's IT infrastructure issues. The web update system facilitated fast and reliable updates from employees on their assigned tasks, resulting in marked improvements in delivery times and team communications.\\n\\nOverall, Caterpillar's IT infrastructure was fragmented, with multiple systems and applications that were not fully integrated, leading to inefficiencies and limitations in data analysis and business decision-making.\"]\n",
      "done\n",
      "                                                text  \\\n",
      "0  Caterpillar, a multinational corporation, acqu...   \n",
      "1  The document describes the IT department of Ca...   \n",
      "2  Caterpillar Tunneling Canada Corporation (CTCC...   \n",
      "3  Caterpillar's business intelligence (BI) platf...   \n",
      "4  Caterpillar Tunneling (CTCC) is a leading prov...   \n",
      "5  The document describes the implementation of a...   \n",
      "6  Here is a detailed summary of the documentatio...   \n",
      "0  Here is a detailed summary of the document:\\n\\...   \n",
      "\n",
      "                                                embd cluster  \n",
      "0  [-0.004161178, -0.032465518, 0.06852721, 0.007...     [0]  \n",
      "1  [-0.0318527, 0.040642403, 0.057710063, 0.01728...     [0]  \n",
      "2  [-0.036361437, -0.035001792, 0.034392707, 0.04...     [0]  \n",
      "3  [-0.014097759, 0.008462368, -0.021284087, 0.02...     [0]  \n",
      "4  [-0.06427016, -0.080042586, 0.03532012, 0.0158...     [0]  \n",
      "5  [-0.048901606, 0.035056725, 0.031306345, -0.01...     [0]  \n",
      "6  [-0.07626325, 0.06345608, -0.0285929, 0.035284...     [0]  \n",
      "0  [-0.026065327, -0.018766472, 0.022851584, -0.0...       0  \n"
     ]
    }
   ],
   "source": [
    "leaf_texts = texts\n",
    "results = recursive_embed_cluster_summarize(leaf_texts, level=1, n_levels=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the results dictioanry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [-0.004161178, -0.032465518, 0.06852721, 0.007...\n",
       "1    [-0.0318527, 0.040642403, 0.057710063, 0.01728...\n",
       "2    [-0.036361437, -0.035001792, 0.034392707, 0.04...\n",
       "3    [-0.014097759, 0.008462368, -0.021284087, 0.02...\n",
       "4    [-0.06427016, -0.080042586, 0.03532012, 0.0158...\n",
       "5    [-0.048901606, 0.035056725, 0.031306345, -0.01...\n",
       "6    [-0.07626325, 0.06345608, -0.0285929, 0.035284...\n",
       "0    [-0.026065327, -0.018766472, 0.022851584, -0.0...\n",
       "Name: embd, dtype: object"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[2][0][\"embd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'W13513   \\n \\n \\nCATERPILLAR TUNNELING: REVI TALIZING USER ADOPTION OF \\nBUSINESS INTELLIGENCE \\n \\n \\nFrances Leung and Murat Kristal wrote this case solely to provide material for class discussion.\\n\\nThe authors do not intend to \\nillustrate either effective or ineffective handling of a manager ial situation.\\n\\nThe authors may have disguised certain names and  other \\nidentifying information to protect confidentiality.\\n\\nThis publication may not be transmitted, photoc opied, digitized or otherwise reproduced in any form or by any means without the  \\npermission of the copyright holder.'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0]\n",
       "1    [0]\n",
       "2    [0]\n",
       "3    [0]\n",
       "4    [0]\n",
       "5    [0]\n",
       "6    [0]\n",
       "Name: cluster, dtype: object"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[2][0][\"cluster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 2])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [-0.004161178, -0.032465518, 0.06852721, 0.007...\n",
      "1    [-0.0318527, 0.040642403, 0.057710063, 0.01728...\n",
      "2    [-0.036361437, -0.035001792, 0.034392707, 0.04...\n",
      "3    [-0.014097759, 0.008462368, -0.021284087, 0.02...\n",
      "4    [-0.06427016, -0.080042586, 0.03532012, 0.0158...\n",
      "5    [-0.048901606, 0.035056725, 0.031306345, -0.01...\n",
      "6    [-0.07626325, 0.06345608, -0.0285929, 0.035284...\n",
      "0    [-0.026065327, -0.018766472, 0.022851584, -0.0...\n",
      "Name: embd, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(results[2][0][\"embd\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing collapased tree retrieval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W13513   \\n \\n \\nCATERPILLAR TUNNELING: REVI TALIZING USER ADOPTION OF \\nBUSINESS INTELLIGENCE \\n \\n \\nFrances Leung and Murat Kristal wrote this case solely to provide material for class discussion.\\n\\nThe authors do not intend to \\nillustrate either effective or ineffective handling of a manager ial situation.\\n\\nThe authors may have disguised certain names and  other \\nidentifying information to protect confidentiality.\\n\\nThis publication may not be transmitted, photoc opied, digitized or otherwise reproduced in any form or by any means without the  \\npermission of the copyright holder.', 'Reproducti on of this material is not covered under  authorization by any reproduction rights  \\norganization.\\n\\nTo order copies or request per mission to reproduce materials, contact Iv ey Publishing, Ivey Business School, West ern \\nUniversity, London, Ontario, Canada, N6G 0N1; (t) 519.661.3208; (e) cases@ivey.ca; www.iveycases.com.', 'Copyright © 2013, Richard Ivey School of Business Foundation Version: 2014-03-31 \\n \\n \\nCaterpillar Tunneling Canada Corpora tion (CTCC), a subsidiary of the U.S. company Caterpillar Inc., had \\nbeen experiencing a host of problems — e.g., data  inconsistency, uneven re porting and poorly defined \\nprocesses — with its outdated enterprise resour ce planning (ERP) system.\\n\\nBetween 2011 and 2012, it \\nplanned to upgrade to its parent company’s SAP but  had to cancel due to resource allocation issues.', 'A \\nbusiness intelligence (BI) platform had been deployed locally as an intermediary solution to facilitate \\nbusiness decision making; after the cancellation, it became  an even more critical tool to complement the \\ntroubled ERP system in transforming raw and dispar ate business data into actionable business insights.', 'Faced with limited information technology (IT) resources,  an inflexible ERP infrastructure, imbalanced \\nuser adoption of BI, and under pressure to generate  timely financial and performance reporting to the \\ncorporate office, Jon McEwan, the CTCC’s business resource manager and head of the finance \\ndepartment, struggled to turn the existing BI solution into the platform of choice for trusted information distribution throughout the company.\\n\\nThe BI platform allowed users to link disparate data sources successfully, but not all business units within \\nthe company were ready to adopt the software.', 'As a result, the different levels of participation, technical \\naptitude and personal motivation created an imbalan ced reporting landscape characterized by two types of \\nusers.\\n\\nOn one hand, the analytics junkies who favoured slicing and dicing interactive datasets on their own and getting hands-on with the late st data visualization utilities.\\n\\nOn the other, the canned report users \\nwho were passive in performing their own analyses or  looking beyond the static results generated, and \\npreferred receiving information from the traditional cha nnels with which they were most familiar.', 'Thus, \\nthe BI platform had become both the go-to platform for effective decision making for some and a source \\nof multiple versions of the truth for others.\\n\\nThis great divide fostered the emergence of “information insiders” who were more proficient in extracting business insights for decision making than those who were less technology-savvy or less adaptive to new tools and processes.\\n\\nTo release the full potential of th e existing BI platform, McEwan had to focus his \\nenergy on user needs and the flaws of the initial BI platform implementation.', 'This document is authorized for use only in Prof Kalpit Sharma©s MSDSM01_Computer and Information Systems at Indian Institute of Management - Amritsar from Dec 2023 to Jun 2024.Page 2 9B13E030  \\n \\n \\n SAP BUSINESS TRANSFORMA TION AT CATERPILLAR \\n \\nFrom 2005 to 2006, Caterpillar emba rked on a business transformation project to implement SAP across \\nits machine and engine businesses to replace a host of legacy systems and to standardize an enterprise-\\nwide ERP platform.1 To facilitate the transformation, Caterp illar established a special taskforce called \\nMACH 1 that would work with new target deployment  sites to localize the Caterpillar SAP template to \\nthe site’s business and legal requirements, support transformation to the enterprise business processes, map and load legacy system data into SAP, participate in system user acceptance testing and train local users.', '2  \\n \\nIn 2010, CTCC was selected as one of the sites to  undergo SAP implementation.\\n\\nA team of key \\nemployees was selected to act as subject matter experts and collaborate with the corporate team and external consultants to assess CTCC’s business processes and determine the gaps that the corporate SAP \\ntemplate would need to overcome.\\n\\nAfter more than a year of localization sessions and data cleansing efforts by the local, corporate and external teams, th e project was put on hold indefinitely, mostly because \\nthe implementation was demanding more local resources from CTCC than previously expected.', 'The \\ndiscontinuation of the project allowed corporate res ources to be offloaded to other sites with higher \\npriorities for SAP transformation.\\n\\nFurthermore, the ga p analysis revealed that CTCC’s unique concurrent \\nengineering and project-based business model would re quire a SAP template to be designed from scratch \\nto facilitate the management of the end-to-end cy cle from design to delivery for tunnel boring machine \\n(TBM) projects, an endeavour unfamiliar to the cor porate and external teams.\\n\\nCTCC was left with no \\nchoice but to operate under its original ERP system with  no plan to invest further in ERP development.', 'CATERPILLAR TUNNELING OVERVIEW \\n \\nFounded in 1972 as Lovat Inc., CTCC was a leadi ng tunneling technologies provider for soft ground to \\nhard rock geological conditions, specializing in th e custom design and manufacture of tunnel boring \\nmachines (TBMs) used in the cons truction of transportation and utility tunnels ranging from two to 12 \\nmetres in diameter.\\n\\nThe company also offered refurb ishments and reselling of TBMs, technical and field \\nservices support, product support and spare parts fulfillment.', 'CTCC was headquartered in Toronto, Canada and employed a staff of 330 people, with sales agents \\nstationed in worldwide locations including Russia, the United Kingdom and China.\\n\\nIt provided management on transit projects globally and contribu ted to infrastructure building such as sewers and \\nunderground cables in places as diverse as China, Egypt and Colombia.\\n\\n3 Mining companies also use \\nTBMs to create mine access.', 'Some of the high prof ile TBM contracts that have been awarded to CTCC \\ninclude the provision of four TBMs for mining an 8.6-kilometre extension of the Toronto Transit Commission’s (TTC) Yonge-University-Spadina subway  from the Downsview Station terminal to the \\nVaughan Metropolitan Centre at Highw ay 7 and the provision of a TBM to Thiess Tunneling for mining a \\n3.2-kilometre cable tunnel under the heart of the central business district in the city of Sydney for Ausgrid, the largest electricity distributor in Australia.', '1 Vertex, “Caterpillar’s Stra tegy for World-Class Value Added Tax Management,” May 2012, \\nwww.vertexinc.com/ResourceCenter/WhitePapers/PDFs/vertex-vat-caterpillar-whi te-paper-dsb-review-v2.pdf, accessed May \\n8, 2013.\\n\\n2 Caterpillar, “Information Technol ogy,” www.caterpillar.com/cda/layout?m=629355&x=7&id=2492888, accessed May 8, \\n2013.\\n\\n3 Kim Laudrum, “Lovat Has Tunnel Vision,”  Plant, February 18, 2008: pp.\\n\\n17—19.2013.\\n\\n3 Kim Laudrum, “Lovat Has Tunnel Vision,”  Plant, February 18, 2008: pp.\\n\\n17—19.', 'This document is authorized for use only in Prof Kalpit Sharma©s MSDSM01_Computer and Information Systems at Indian Institute of Management - Amritsar from Dec 2023 to Jun 2024.Page 3 9B13E030  \\n \\n \\n In 2008, Caterpillar Inc. announced the entry into the tunnel boring business through the acquisition of \\nLovat Inc. At the time of acquisition, Caterpillar in tended to leverage its gl obal purchasing organization, \\nits global reach and its experience in large-scale manu facturing processes to support and invest in Lovat’s \\nproduct line and in the tunnel boring business.', 'Lova t was later renamed the Caterpillar Tunneling Canada \\nCorporation and became a part of Caterpillar’s Dive rsified Products Division, alongside forestry, paving, \\nwork tools, original equipment manufacturer (OEM) so lutions and defense, and re lated federal products.\\n\\nAs a privately owned company for more than 34 year s, Lovat operated as a family business and lacked \\nthe organizational governance characterized by a multinational corporation like Caterpillar.\\n\\nMany \\nactivities were carried out in a reactive manner.\\n\\nSome decision making was also dominated by \\nundocumented tribal knowledge.', 'As CTCC integrated more closely into its parent company with operations that were highly methodical and procedural, the need to streamline and standardize some of the \\nexisting processes grew.\\n\\nAt the same time, the parent company realized that CTCC’s concurrent engineering and project-based model was vastly different from Caterpillar’s repetitive manufacturing \\nmodel.\\n\\nTherefore, not all established manufacturing protocols could be directly applied to CTCC.\\n\\nOne of the biggest reforms was in how project management was facilitated.\\n\\nThe core of CTCC’s business \\nwas to deliver custom tunnel boring solutions to its clients.', 'Every TBM was unique and had varying \\nproject requirements including the geological condition of the ground, the size of the tunnel, restrictions to site access, sensitivity of the buyer to the overall cost, etc.\\n\\n4 All these factors could affect the type of \\nmachine selected and its configuration.\\n\\nPrior to the acquisition, the project management process was \\nrather lax and lacked the consistency and rigour of re gular status reporting.\\n\\nIt could be months after the \\nproject was completed before the project management team realized that the project was significantly over budget.', 'To ensure that the different projects with varying scopes that were running in parallel were all delivered \\non time, with the highest quality and on budget, a st andard project management methodology needed to \\nbe established for tighter control on project schedu ling, assignments of tasks, reporting of statuses and \\nidentification of bottlenecks.\\n\\nAn external cons ultant was brought in to assess CTCC’s project \\nmanagement needs and facilitate a series of training  programs on project duration planning and control, \\nresource and cost management, team  communications and dynamics, as we ll as project risk management.', 'A proprietary web update system from the consultant was implemented to enable  fast and reliable updates \\nfrom employees on their assigned tasks.\\n\\nMarked impr ovement was observed on de livery times and team \\ncommunications.\\n\\nBUSINESS SYSTEMS LANDSCAPE \\n \\nA number of companywide information systems had been implemented over the years to meet the \\nexpanding needs of business users.\\n\\nThere were two pr edecessors to the existing integrated ERP system.\\n\\nThe earliest was a homegrown Microsoft Access data base that managed engineering parts creation and \\nbasic work order processing.', 'It was followed by a cu stom business system with additional functionalities \\ndesigned by a contracted software company.\\n\\nSince not all historical data was migrated to the latest ERP \\nsystem, the predecessors remained accessible to sel ected users for the sole purpose of information \\nretrieval.\\n\\nAside from the ERP system, there was also  a custom quality assurance (QA) system for keeping \\ntrack of nonconformance records (NCRs).\\n\\nThe QA syst em had very basic functionalities for the creationtrack of nonconformance records (NCRs).', 'The QA syst em had very basic functionalities for the creation \\nof NCRs and the assignment of advocates for resolving them.\\n\\nIt did not provide reporting functionalities.\\n\\n4 Rick P. Lovat, “TBM Design Considerat ions: Selection of Earth Pressure Balance or Slurry Pressure Balance Tunnel \\nBoring Machines,” International Symposium on Utilization of Underground Space in Urban Areas, Sharm El Sheikh, 2006.', 'This document is authorized for use only in Prof Kalpit Sharma©s MSDSM01_Computer and Information Systems at Indian Institute of Management - Amritsar from Dec 2023 to Jun 2024.Page 4 9B13E030  \\n \\n \\n The data captured by the QA database was virtually  untapped in spotting trends of the origins of \\nnonconformance incidents.\\n\\nThe latest ERP system consisted of modules including project management, sales order processing, item \\nmaster data, finance, material purchasing, produc tion planning, inventory management, shipping and \\nreceiving and time and administration.\\n\\nAll transactiona l business data were captured by this system.', 'The implementation of the ERP system was completed in 2005 and was carried out by an ad hoc team of handpicked employees who were knowledgeable about  the company’s operations.\\n\\nThe specific ERP \\npackage was selected by the executive members of the company, primarily due to the attractive offer from \\nthe software company that was at the time expanding  its business in North America.\\n\\nWhile the original \\nERP package was designed for the European market, the software compan y wanted to partner with Lovat \\nto launch a pilot program that aimed at customizi ng the ERP package to suit the needs of Canadian \\ncompanies.', 'For example, the taxation configuration had to be tailored for the Canadian market.\\n\\nLovat also \\nrequested other parts of the ERP system to be custom ized to conform to its business processes.\\n\\nThe result \\nof the extensive customization was unpredictable syst em behaviours that the end users and the local ERP \\nsupport team had to bear, resulting in prolonged dissa tisfaction and complaints.\\n\\nERP implementation had \\nsince been a touchy subject in the company.\\n\\nThe cancellation of the SAP implementation further \\nintensified employees’ dismay.', 'There were other silo applications or utilities devel oped and used by departments for their own internal \\nprocesses that the ERP system was not adequate to  support.\\n\\nFor example, the TBM sales department \\nestablished its own quotation tools for TBM contracts,  and the power and controls systems engineering \\nunit created its own electronics and hydraulics parts database for facilitating the design process of electrical and hydraulic assemblies.\\n\\nBoth u tilized data feeds from the ERP system (see \\nExhibit 1 ).\\n\\nINFORMATION TECHNOLOGY DEPARTMENT \\n \\nIT was not regarded as a strategic business unit but me rely a supportive function at CTCC.', 'Prior to the \\nacquisition, the IT department reported to the operati ons manager, who was responsible for operations in \\nall production facilities and for mainte nance and capital expenditure for buildings and equipment.\\n\\nTypical \\nIT activities included setup and maintenance of com puter hardware and peri pherals, web and network \\nadministration, software installations and upgr ades, phone system management, systems security \\nmanagement, IT asset management and helpdesk support,  etc.\\n\\nAfter the acquisition, the IT department \\ntemporarily reported to the business resource manage r who led the finance department.', 'It was later \\nreorganized and became part of the parent compan y’s Global Information Services (GIS) unit.\\n\\nWhile it \\nremained in Toronto, it was under the supervision of  Simon Swiss, an IT manager from GIS located in \\nPeoria, Illinois.\\n\\nIts responsibilities also expanded to support a number of Caterpillar facilities outside of \\nToronto.\\n\\nThe reorganization provided an opportunity for CTCC’ s IT department to gain a wider exposure to the \\nvast IT resources of the parent company and learn to adopt the standard operating procedures established \\nby GIS.', 'Swiss also became the key contact to help  CTCC navigate the corporate IT landscape that was \\nconfusing to the local members due to the large num ber of subdivisions.\\n\\nThe most prominent change was \\non network and web security.\\n\\nBy bringing CTCC’s ne twork behind Caterpillar’s corporate firewall, the \\nflow of incoming and outgoing netw ork traffic was secured.\\n\\nAside from an IT audit performed on CTCC’s computer network, there was no formal assessmentflow of incoming and outgoing netw ork traffic was secured.', 'Aside from an IT audit performed on CTCC’s computer network, there was no formal assessment \\nperformed on the company’s overall information mana gement needs to determine how the subsidiary \\nThis document is authorized for use only in Prof Kalpit Sharma©s MSDSM01_Computer and Information Systems at Indian Institute of Management - Amritsar from Dec 2023 to Jun 2024.', \"Caterpillar, a multinational corporation, acquired Lovat Inc., a tunnel boring company, in 2008 to leverage its global purchasing organization, reach, and manufacturing experience to support and invest in Lovat's product line. Lovat was later renamed Caterpillar Tunneling Canada Corporation and became part of Caterpillar's Diversified Products Division. However, Lovat, as a privately-owned family business for over 34 years, lacked the organizational governance and structure of a multinational corporation like Caterpillar. It operated in a reactive manner, with many activities carried out without formal processes, and decision-making was often dominated by undocumented tribal knowledge. This posed a challenge for Caterpillar as it sought to integrate Lovat into its organization and adopt business intelligence practices to improve decision-making and drive growth.\", \"The document describes the IT department of Caterpillar (CTCC) before and after an acquisition. Prior to the acquisition, the IT department reported to the operations manager, who oversaw production facilities, maintenance, and capital expenditures. The IT department's responsibilities included setting up and maintaining computer hardware and peripherals, web and network administration, software installations and upgrades, phone system management, systems security management, IT asset management, and helpdesk support.\\n\\nAfter the acquisition, the IT department temporarily reported to the business resource manager, who led the finance department. Notably, there was no formal assessment of the company's overall information management needs, except for an IT audit performed on CTCC's computer network. This lack of assessment meant that the subsidiary's information management needs were not thoroughly evaluated, leaving potential gaps in the company's IT infrastructure and operations.\", \"Caterpillar Tunneling Canada Corporation (CTCC), a subsidiary of Caterpillar Inc., faced numerous issues with its outdated enterprise resource planning (ERP) system, including data inconsistencies, uneven reporting, and poorly defined processes. Between 2011 and 2012, CTCC planned to upgrade to its parent company's SAP system but had to cancel due to resource allocation issues.\\n\\nIn 2010, CTCC was selected as one of the sites to undergo SAP implementation as part of Caterpillar's business transformation project. A team of key employees worked with corporate and external consultants to assess CTCC's business processes and identify gaps in the corporate SAP template. However, the project was put on hold indefinitely due to the demanding local resources required and the need for a customized SAP template to facilitate CTCC's unique concurrent engineering and project-based business model.\\n\\nAs a result, CTCC was left with no choice but to continue operating under its original ERP system with no plans to invest further in ERP development. However, the need to streamline and standardize processes grew as CTCC integrated more closely with its parent company. One of the biggest reforms was in project management, where a standardized methodology was established to ensure projects were delivered on time, with high quality, and on budget.\\n\\nAn external consultant was brought in to assess CTCC's project management needs and facilitate training programs on project duration planning and control, resource and cost management, team communications and dynamics, and project risk management. This was necessary because CTCC's project management process was previously lax and lacked consistency, often resulting in projects being significantly over budget.\", 'Caterpillar\\'s business intelligence (BI) platform was deployed as an intermediate solution to facilitate business decision making, but it became even more critical after the cancellation of the ERP system. The platform helped transform raw and disparate business data into actionable insights, but it faced challenges due to limited IT resources, an inflexible ERP infrastructure, and imbalanced user adoption.\\n\\nThe BI platform allowed users to link disparate data sources, but its adoption varied across business units, creating an imbalanced reporting landscape. This led to two types of users: \"analytics junkies\" who were tech-savvy and hands-on with data visualization utilities, and \"canned report users\" who were passive and preferred traditional channels.\\n\\nThe platform became both a go-to tool for effective decision making for some and a source of multiple versions of the truth for others. This created \"information insiders\" who were more proficient in extracting business insights than others. To fully utilize the BI platform, Jon McEwan, the business resource manager, had to focus on user needs and address the flaws of the initial implementation.', \"Caterpillar Tunneling (CTCC) is a leading provider of tunneling technologies, founded in 1972 as Lovat Inc. The company specializes in the custom design and manufacture of tunnel boring machines (TBMs) for soft ground to hard rock geological conditions, with diameters ranging from 2 to 12 meters. CTCC offers refurbishments and reselling of TBMs, technical and field services support, product support, and spare parts fulfillment. Headquartered in Toronto, Canada, the company employs 330 people and has sales agents worldwide, including Russia, the UK, and China.\\n\\nCTCC has contributed to various infrastructure projects globally, including transportation and utility tunnels, sewers, and underground cables in countries such as China, Egypt, and Colombia. The company has also provided management services for transit projects and has worked with mining companies to create mine access using TBMs.\\n\\nSome notable TBM contracts awarded to CTCC include the provision of four TBMs for the Toronto Transit Commission's Yonge-University-Spadina subway extension and a TBM for mining a cable tunnel under the heart of Sydney's central business district.\\n\\nThe company's quality assurance (QA) system had basic functionalities for creating non-conformance reports (NCRs) and assigning advocates for resolving them, but lacked reporting functionalities. The QA system was later reorganized and became part of Caterpillar's Global Information Services (GIS) unit, with expanded responsibilities to support multiple Caterpillar facilities outside of Toronto.\\n\\nThe reorganization brought about significant changes, including improved network and web security. CTCC's network was brought behind Caterpillar's corporate firewall, securing the flow of incoming and outgoing network traffic. An IT audit was performed on CTCC's computer network, and the company gained access to Caterpillar's vast IT resources, adopting standard operating procedures established by GIS.\", \"The document describes the implementation of a proprietary web update system and the evolution of Caterpillar's business systems landscape.\\n\\nThe web update system was introduced to facilitate fast and reliable updates from employees on their assigned tasks, resulting in marked improvements in delivery times and team communications.\\n\\nPrior to the current integrated ERP system, the company had two predecessor systems. The first was a homegrown Microsoft Access database that managed engineering parts creation and basic work order processing. The second system was an ERP package implemented in 2005 by a team of handpicked employees knowledgeable about the company's operations. The ERP package was selected by the executive members, primarily due to an attractive offer from the software company, which was expanding its business in North America at the time.\\n\\nNotably, the original ERP package was designed for the European market, but the software company partnered with Caterpillar to launch a pilot program to customize the ERP package to suit the needs of Canadian companies.\", \"Here is a detailed summary of the documentation:\\n\\nCaterpillar, a company, had a complex IT infrastructure consisting of multiple systems, including a custom business system, an ERP system, and a quality assurance (QA) system. The ERP system was implemented with extensive customization to conform to the company's business processes, including modules for project management, sales order processing, finance, and production planning. However, the customization led to unpredictable system behaviors, causing prolonged dissatisfaction and complaints among end-users and the local ERP support team.\\n\\nThe QA system was used to track nonconformance records, but its basic functionalities limited its ability to identify trends and patterns in nonconformance incidents. Additionally, there were other silo applications and utilities developed and used by departments for their internal processes, which were not supported by the ERP system. These included a quotation tool for TBM contracts and an electronics and hydraulics parts database for design processes.\\n\\nThe IT department at Caterpillar was not considered a strategic business unit but rather a supportive function, and the company's approach to IT was reactive rather than proactive. The implementation of the ERP system was a sensitive topic, and its cancellation further intensified employee dissatisfaction. The company's historical data was not fully migrated to the latest ERP system, and predecessors remained accessible for information retrieval purposes. Overall, Caterpillar's IT infrastructure was fragmented, with multiple systems and applications that were not fully integrated, leading to inefficiencies and limitations in data analysis and business decision-making.\", \"Here is a detailed summary of the document:\\n\\nCaterpillar, a multinational corporation, acquired Lovat Inc., a tunnel boring company, in 2008. However, the integration of Lovat into Caterpillar's organization was challenging due to Lovat's lack of organizational governance and structure. Lovat, renamed Caterpillar Tunneling Canada Corporation (CTCC), operated in a reactive manner with many activities carried out without formal processes, and decision-making was often dominated by undocumented tribal knowledge.\\n\\nThe IT department at CTCC faced numerous issues, including an outdated enterprise resource planning (ERP) system, which was eventually cancelled due to resource allocation issues. The company was left with an old ERP system with no plans for further development. However, the need to streamline and standardize processes grew as CTCC integrated more closely with its parent company.\\n\\nTo address these issues, Caterpillar's business intelligence (BI) platform was deployed as an intermediate solution to facilitate business decision making. However, the platform faced challenges due to limited IT resources, an inflexible ERP infrastructure, and imbalanced user adoption.\\n\\nCTCC, a leading provider of tunneling technologies, specializes in the custom design and manufacture of tunnel boring machines (TBMs) for soft ground to hard rock geological conditions. The company has contributed to various infrastructure projects globally, including transportation and utility tunnels, sewers, and underground cables.\\n\\nThe company's quality assurance (QA) system had basic functionalities but lacked reporting functionalities. The QA system was later reorganized and became part of Caterpillar's Global Information Services (GIS) unit, with expanded responsibilities to support multiple Caterpillar facilities outside of Toronto.\\n\\nThe implementation of a proprietary web update system and the evolution of Caterpillar's business systems landscape also played a significant role in addressing the company's IT infrastructure issues. The web update system facilitated fast and reliable updates from employees on their assigned tasks, resulting in marked improvements in delivery times and team communications.\\n\\nOverall, Caterpillar's IT infrastructure was fragmented, with multiple systems and applications that were not fully integrated, leading to inefficiencies and limitations in data analysis and business decision-making.\"]\n"
     ]
    }
   ],
   "source": [
    "# Initialize all_texts with leaf_texts\n",
    "all_texts = leaf_texts.copy()\n",
    "\n",
    "# Iterate through the results to extract summaries from each level and add them to all_texts\n",
    "for level in sorted(results.keys()):\n",
    "    # Extract summaries from the current level's DataFrame\n",
    "    summaries = results[level][1][\"summaries\"].tolist()\n",
    "    # Extend all_texts with the summaries from the current level\n",
    "    all_texts.extend(summaries)\n",
    "#Final Summaries extracted\n",
    "print(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(leaf_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here is a detailed summary of the document:\\n\\nCaterpillar, a multinational corporation, acquired Lovat Inc., a tunnel boring company, in 2008. However, the integration of Lovat into Caterpillar's organization was challenging due to Lovat's lack of organizational governance and structure. Lovat, renamed Caterpillar Tunneling Canada Corporation (CTCC), operated in a reactive manner with many activities carried out without formal processes, and decision-making was often dominated by undocumented tribal knowledge.\\n\\nThe IT department at CTCC faced numerous issues, including an outdated enterprise resource planning (ERP) system, which was eventually cancelled due to resource allocation issues. The company was left with an old ERP system with no plans for further development. However, the need to streamline and standardize processes grew as CTCC integrated more closely with its parent company.\\n\\nTo address these issues, Caterpillar's business intelligence (BI) platform was deployed as an intermediate solution to facilitate business decision making. However, the platform faced challenges due to limited IT resources, an inflexible ERP infrastructure, and imbalanced user adoption.\\n\\nCTCC, a leading provider of tunneling technologies, specializes in the custom design and manufacture of tunnel boring machines (TBMs) for soft ground to hard rock geological conditions. The company has contributed to various infrastructure projects globally, including transportation and utility tunnels, sewers, and underground cables.\\n\\nThe company's quality assurance (QA) system had basic functionalities but lacked reporting functionalities. The QA system was later reorganized and became part of Caterpillar's Global Information Services (GIS) unit, with expanded responsibilities to support multiple Caterpillar facilities outside of Toronto.\\n\\nThe implementation of a proprietary web update system and the evolution of Caterpillar's business systems landscape also played a significant role in addressing the company's IT infrastructure issues. The web update system facilitated fast and reliable updates from employees on their assigned tasks, resulting in marked improvements in delivery times and team communications.\\n\\nOverall, Caterpillar's IT infrastructure was fragmented, with multiple systems and applications that were not fully integrated, leading to inefficiencies and limitations in data analysis and business decision-making.\""
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts[37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [-0.004161178, -0.032465518, 0.06852721, 0.007...\n",
       "1    [-0.0318527, 0.040642403, 0.057710063, 0.01728...\n",
       "2    [-0.036361437, -0.035001792, 0.034392707, 0.04...\n",
       "3    [-0.014097759, 0.008462368, -0.021284087, 0.02...\n",
       "4    [-0.06427016, -0.080042586, 0.03532012, 0.0158...\n",
       "5    [-0.048901606, 0.035056725, 0.031306345, -0.01...\n",
       "6    [-0.07626325, 0.06345608, -0.0285929, 0.035284...\n",
       "0    [-0.026065327, -0.018766472, 0.022851584, -0.0...\n",
       "Name: embd, dtype: object"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[2][0][\"embd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['W13513   \\n \\n \\nCATERPILLAR TUNNELING: REVI TALIZING USER ADOPTION OF \\nBUSINESS INTELLIGENCE \\n \\n \\nFrances Leung and Murat Kristal wrote this case solely to provide material for class discussion.\\n\\nThe authors do not intend to \\nillustrate either effective or ineffective handling of a manager ial situation.\\n\\nThe authors may have disguised certain names and  other \\nidentifying information to protect confidentiality.\\n\\nThis publication may not be transmitted, photoc opied, digitized or otherwise reproduced in any form or by any means without the  \\npermission of the copyright holder.',\n",
       " 'Reproducti on of this material is not covered under  authorization by any reproduction rights  \\norganization.\\n\\nTo order copies or request per mission to reproduce materials, contact Iv ey Publishing, Ivey Business School, West ern \\nUniversity, London, Ontario, Canada, N6G 0N1; (t) 519.661.3208; (e) cases@ivey.ca; www.iveycases.com.',\n",
       " 'Copyright © 2013, Richard Ivey School of Business Foundation Version: 2014-03-31 \\n \\n \\nCaterpillar Tunneling Canada Corpora tion (CTCC), a subsidiary of the U.S. company Caterpillar Inc., had \\nbeen experiencing a host of problems — e.g., data  inconsistency, uneven re porting and poorly defined \\nprocesses — with its outdated enterprise resour ce planning (ERP) system.\\n\\nBetween 2011 and 2012, it \\nplanned to upgrade to its parent company’s SAP but  had to cancel due to resource allocation issues.',\n",
       " 'A \\nbusiness intelligence (BI) platform had been deployed locally as an intermediary solution to facilitate \\nbusiness decision making; after the cancellation, it became  an even more critical tool to complement the \\ntroubled ERP system in transforming raw and dispar ate business data into actionable business insights.']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating MILVUS Database\n",
    "\n",
    "- Install docker desktop\n",
    "- Download the script to the directory of your project (provided in Milvus documentation), note :got to docker compose\n",
    "- Open your terminal\n",
    "- Now run docker compose up -d  (not to include sudo)\n",
    "- These will create and start the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymilvus\n",
      "  Downloading pymilvus-2.4.4-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting setuptools>=67 (from pymilvus)\n",
      "  Downloading setuptools-71.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting grpcio<=1.63.0,>=1.49.1 (from pymilvus)\n",
      "  Downloading grpcio-1.63.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting protobuf>=3.20.0 (from pymilvus)\n",
      "  Downloading protobuf-5.27.2-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting environs<=9.5.0 (from pymilvus)\n",
      "  Downloading environs-9.5.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting ujson>=2.0.0 (from pymilvus)\n",
      "  Using cached ujson-5.10.0-cp312-cp312-win_amd64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: pandas>=1.2.4 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from pymilvus) (2.2.2)\n",
      "Requirement already satisfied: marshmallow>=3.0.0 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from environs<=9.5.0->pymilvus) (3.21.3)\n",
      "Collecting python-dotenv (from environs<=9.5.0->pymilvus)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from pandas>=1.2.4->pymilvus) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from pandas>=1.2.4->pymilvus) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from pandas>=1.2.4->pymilvus) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from pandas>=1.2.4->pymilvus) (2024.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from marshmallow>=3.0.0->environs<=9.5.0->pymilvus) (24.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus) (1.16.0)\n",
      "Downloading pymilvus-2.4.4-py3-none-any.whl (196 kB)\n",
      "   ---------------------------------------- 0.0/196.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 196.0/196.0 kB 11.6 MB/s eta 0:00:00\n",
      "Downloading environs-9.5.0-py2.py3-none-any.whl (12 kB)\n",
      "Downloading grpcio-1.63.0-cp312-cp312-win_amd64.whl (3.9 MB)\n",
      "   ---------------------------------------- 0.0/3.9 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 1.1/3.9 MB 23.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.4/3.9 MB 25.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.9/3.9 MB 31.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.9/3.9 MB 24.7 MB/s eta 0:00:00\n",
      "Downloading protobuf-5.27.2-cp310-abi3-win_amd64.whl (426 kB)\n",
      "   ---------------------------------------- 0.0/426.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 426.9/426.9 kB 26.0 MB/s eta 0:00:00\n",
      "Downloading setuptools-71.1.0-py3-none-any.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ------------------------------- -------- 1.9/2.3 MB 59.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 37.6 MB/s eta 0:00:00\n",
      "Using cached ujson-5.10.0-cp312-cp312-win_amd64.whl (42 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: ujson, setuptools, python-dotenv, protobuf, grpcio, environs, pymilvus\n",
      "Successfully installed environs-9.5.0 grpcio-1.63.0 protobuf-5.27.2 pymilvus-2.4.4 python-dotenv-1.0.1 setuptools-71.1.0 ujson-5.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "pip install pymilvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, db\n",
    "\n",
    "conn = connections.connect(host=\"127.0.0.1\", port=19530)\n",
    "\n",
    "database = db.create_database(\"my_database\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.using_database(\"my_database\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to handle error\n",
    "\n",
    "from pymilvus import Collection, utility\n",
    "\n",
    "# Delete existing collection\n",
    "if utility.has_collection(\"text_embeddings\"):\n",
    "    utility.drop_collection(\"text_embeddings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Milvus schema\n",
    "\n",
    "from pymilvus import FieldSchema, CollectionSchema, DataType,Collection\n",
    "\n",
    "#Define schema for the collection\n",
    "\n",
    "fields = [\n",
    "    FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=False),\n",
    "    FieldSchema(name=\"text_all\", dtype=DataType.VARCHAR, max_length=5000),\n",
    "    FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=384)\n",
    "\n",
    "]\n",
    "\n",
    "schema = CollectionSchema(fields, description=\"Text embeddings collection\")\n",
    "\n",
    "# Create the collection\n",
    "text_collection = Collection(name=\"text_embeddings\", schema=schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [-0.004161178, -0.032465518, 0.06852721, 0.007...\n",
       "1    [-0.0318527, 0.040642403, 0.057710063, 0.01728...\n",
       "2    [-0.036361437, -0.035001792, 0.034392707, 0.04...\n",
       "3    [-0.014097759, 0.008462368, -0.021284087, 0.02...\n",
       "4    [-0.06427016, -0.080042586, 0.03532012, 0.0158...\n",
       "5    [-0.048901606, 0.035056725, 0.031306345, -0.01...\n",
       "6    [-0.07626325, 0.06345608, -0.0285929, 0.035284...\n",
       "0    [-0.026065327, -0.018766472, 0.022851584, -0.0...\n",
       "Name: embd, dtype: object"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[2][0][\"embd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data for ingestion\n",
    "\n",
    "text_embeddings=[]\n",
    "\n",
    "for level in sorted(results.keys()):\n",
    "    # Extract summaries from the current level's DataFrame\n",
    "    embeddings_text = results[level][0][\"embd\"].tolist()\n",
    "    text_embeddings.extend(embeddings_text)\n",
    "    \n",
    "\n",
    "def prepare_data(all_texts,text_embeddings):\n",
    "    ids= list(range(len(all_texts)))\n",
    "    return ids, all_texts,text_embeddings\n",
    "\n",
    "data= prepare_data(all_texts,text_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.39069560e-02,  6.29109368e-02,  4.28803861e-02,  5.84514029e-02,\n",
       "       -3.64153534e-02, -6.02698438e-02,  6.76553547e-02, -7.35528097e-02,\n",
       "       -7.25650368e-03,  3.86103406e-03,  7.90068209e-02, -4.50761691e-02,\n",
       "        1.75856110e-02, -3.91201265e-02, -1.21212872e-02,  6.47031441e-02,\n",
       "        3.04524996e-03, -2.58772485e-02, -9.02550668e-02, -1.19003840e-01,\n",
       "       -4.64027934e-02, -8.71257111e-02, -5.26855141e-02, -2.94602625e-02,\n",
       "       -1.56579405e-01, -6.41241074e-02, -3.05861235e-02,  3.19696106e-02,\n",
       "       -2.15754919e-02, -1.06856309e-01, -3.50361317e-02,  7.93136805e-02,\n",
       "       -2.15596221e-02,  7.01219887e-02,  5.56531847e-02, -3.45781678e-04,\n",
       "       -2.64556129e-02,  2.92465072e-02,  6.88465163e-02, -3.29224207e-02,\n",
       "        4.13506180e-02, -9.23202932e-02, -1.43083045e-02, -2.71362960e-02,\n",
       "       -7.15717226e-02,  1.80034507e-02,  4.80280584e-03, -3.23075950e-02,\n",
       "       -9.24287960e-02,  5.96894100e-02, -1.22276068e-01, -5.61514450e-03,\n",
       "        3.38424630e-02,  8.81824992e-04,  6.65517151e-03, -3.35050896e-02,\n",
       "        7.20809698e-02,  4.72434796e-03, -3.77376042e-02,  2.19532121e-02,\n",
       "        3.58514786e-02,  2.81241331e-02, -1.51957879e-02,  2.95541026e-02,\n",
       "       -2.43165959e-02, -4.25855629e-03, -6.77063018e-02, -4.76170555e-02,\n",
       "        1.74630657e-02, -5.25780544e-02,  7.74491951e-02, -1.18933409e-01,\n",
       "       -4.11934517e-02, -4.78554377e-03,  4.90619875e-02, -1.95585694e-02,\n",
       "       -2.20427364e-02,  3.75991575e-02,  8.90943259e-02, -7.09748641e-02,\n",
       "        5.66545455e-03,  6.10972978e-02,  9.44565982e-03,  5.46937808e-02,\n",
       "       -6.00257069e-02, -4.84286547e-02, -1.82667351e-03, -5.28978035e-02,\n",
       "        6.62946850e-02,  5.50837852e-02,  2.30383724e-02, -6.41788468e-02,\n",
       "        3.30194905e-02,  2.56384118e-03,  2.95700096e-02, -3.65198702e-02,\n",
       "       -2.52488200e-02, -2.82094674e-03, -7.07523152e-02,  8.64035711e-02,\n",
       "       -1.60207171e-02,  8.50068107e-02, -2.45340113e-02,  2.65832967e-03,\n",
       "       -2.04875786e-02, -7.29206726e-02,  8.49391147e-02,  7.47514842e-03,\n",
       "        1.10591473e-02,  4.40699533e-02, -2.08594538e-02, -1.85115263e-02,\n",
       "        6.85226684e-03, -6.06644489e-02, -1.45681351e-02, -7.85855278e-02,\n",
       "       -1.04809776e-01,  5.53936288e-02,  6.97814971e-02,  1.60530210e-02,\n",
       "        5.19406684e-02,  3.50818783e-02, -1.82048455e-02, -3.07654627e-02,\n",
       "       -7.23236278e-02, -1.27742421e-02, -1.87491681e-02,  6.61590114e-33,\n",
       "        7.02465838e-03,  1.63994748e-02, -8.16901252e-02,  8.83159563e-02,\n",
       "        4.04599905e-02,  1.41381351e-02, -3.68807204e-02, -1.65867489e-02,\n",
       "        4.55143824e-02,  1.50190005e-02, -9.15975031e-03,  1.67931113e-02,\n",
       "       -1.02266800e-02, -4.34678309e-02,  4.48314771e-02,  1.73055921e-02,\n",
       "        1.97595544e-02,  8.73054191e-02, -1.76737476e-02,  1.32494047e-03,\n",
       "        8.64847377e-02, -9.17784199e-02,  2.74930485e-02, -7.50695616e-02,\n",
       "        5.51164150e-02,  9.02977213e-02, -3.91193219e-02, -1.96547043e-02,\n",
       "        9.71248597e-02,  4.89893369e-02,  1.29846752e-01, -2.58445125e-02,\n",
       "        4.62915413e-02,  5.08059077e-02, -1.71770342e-02,  1.14103921e-01,\n",
       "       -4.96632233e-02, -4.59591448e-02, -1.08003302e-03, -2.77258139e-02,\n",
       "       -8.46936554e-02, -4.51924428e-02,  5.68762496e-02,  8.56472529e-04,\n",
       "       -9.12898257e-02,  1.33056368e-03,  7.82128330e-03, -4.06713821e-02,\n",
       "        6.94601238e-02, -2.42208820e-02,  2.35846005e-02,  4.10578102e-02,\n",
       "        4.95106243e-02, -2.33987303e-04,  9.82953832e-02, -3.33745368e-02,\n",
       "        3.89834680e-02, -4.60553356e-02,  2.87280083e-02,  3.25680859e-02,\n",
       "       -3.19037260e-03, -6.52988302e-03, -4.59808074e-02,  1.10218242e-01,\n",
       "        1.10274747e-01, -3.92822325e-02, -2.58538611e-02, -2.77817920e-02,\n",
       "        1.03402603e-02, -4.09794524e-02, -3.82428914e-02, -6.96761906e-03,\n",
       "        5.17039970e-02,  4.60802913e-02, -7.89802969e-02, -4.94439341e-02,\n",
       "       -6.23076968e-02,  6.52495772e-02, -2.99639674e-03, -7.45144114e-03,\n",
       "        1.54363038e-02, -3.02674491e-02,  6.35090023e-02, -5.07778376e-02,\n",
       "       -4.43983003e-02,  7.79157737e-03,  6.12415448e-02,  1.96504872e-02,\n",
       "        1.48770753e-02,  1.18305214e-01, -6.54592589e-02,  5.51818013e-02,\n",
       "       -3.01300432e-03,  1.58814698e-01, -4.10918938e-03, -7.75677278e-33,\n",
       "       -4.96357605e-02,  4.63816104e-03,  5.88224456e-03, -8.36306661e-02,\n",
       "       -5.61655909e-02,  2.76991725e-02,  2.49970630e-02,  1.69436410e-02,\n",
       "       -1.64296143e-02,  7.16346204e-02, -3.64194997e-02,  1.88129991e-02,\n",
       "        4.57545221e-02, -1.99022470e-03, -1.47568947e-02,  1.30442269e-02,\n",
       "        1.41903535e-01, -9.11199600e-02, -2.44777016e-02,  7.39275292e-02,\n",
       "       -7.34502962e-03,  3.24650519e-02, -1.39785424e-01,  4.60580699e-02,\n",
       "       -1.01364935e-02,  7.07444027e-02,  2.83799767e-02, -2.25527026e-02,\n",
       "       -4.89632562e-02, -1.63932014e-02, -3.15899849e-02, -6.17896840e-02,\n",
       "       -1.16032772e-02,  7.22819660e-03, -3.07012610e-02, -6.07391931e-02,\n",
       "       -6.46337122e-03,  7.74843356e-05, -7.36272410e-02,  2.42767669e-02,\n",
       "        3.34704630e-02, -5.50418720e-03, -6.28385320e-02, -5.60240168e-03,\n",
       "        2.89991405e-02,  1.99059956e-02, -2.17524301e-02, -8.98683667e-02,\n",
       "       -4.96860519e-02, -7.61939436e-02, -2.54566632e-02, -9.05493507e-05,\n",
       "       -1.94944367e-02, -6.04550280e-02, -2.35779118e-02,  1.10015579e-01,\n",
       "       -4.45741508e-03, -1.34165417e-02, -2.50191931e-02, -3.70179117e-02,\n",
       "        5.40733114e-02, -1.45848095e-02,  4.88691516e-02,  5.72845899e-02,\n",
       "       -2.43210811e-02,  5.83760291e-02,  5.66707412e-03, -8.82057324e-02,\n",
       "       -6.12778477e-02, -5.44640310e-02,  8.35080966e-02, -5.11653675e-03,\n",
       "       -4.58069984e-03, -7.69932270e-02,  5.77541180e-02,  6.50108187e-03,\n",
       "        2.02439912e-02, -3.22602242e-02, -7.56668374e-02, -4.79492880e-02,\n",
       "        6.44526184e-02, -5.15031889e-02,  1.79616325e-02,  4.17711139e-02,\n",
       "        7.23063108e-03, -1.09141460e-02,  4.73823845e-02, -1.60744484e-03,\n",
       "       -6.29002973e-03, -6.03208318e-02, -4.53715771e-02, -5.47990873e-02,\n",
       "       -7.93986619e-02,  2.66978163e-02,  1.58194099e-02, -5.89081566e-08,\n",
       "       -2.86982227e-02,  1.72190350e-02,  2.94592641e-02, -1.93844493e-02,\n",
       "        1.16632795e-02,  8.97970423e-03, -2.06220523e-02, -7.82782398e-03,\n",
       "        1.73660263e-03,  6.15745783e-02,  8.99095088e-03, -4.01273184e-02,\n",
       "       -7.33894780e-02,  8.86188224e-02,  2.78924201e-02, -1.30640389e-02,\n",
       "       -2.00586934e-02,  3.80937173e-03, -5.81208325e-04,  2.09854711e-02,\n",
       "       -4.69650999e-02,  5.83428219e-02,  2.97753010e-02,  1.09151332e-03,\n",
       "       -9.21530533e-04,  1.58434187e-03, -3.63993868e-02, -5.19566014e-02,\n",
       "       -2.38010064e-02,  5.66427149e-02, -2.51295101e-02,  5.31394742e-02,\n",
       "        5.87911047e-02,  4.72023450e-02, -4.74931225e-02,  9.92470905e-02,\n",
       "        1.10457102e-02, -7.40031227e-02, -7.72690773e-03,  4.65695001e-02,\n",
       "       -1.11979963e-02,  7.64418915e-02,  1.91707816e-02,  4.56284136e-02,\n",
       "        3.33599299e-02,  7.06867501e-03, -1.57395788e-02, -3.44812535e-02,\n",
       "        3.70500772e-03,  3.77202267e-03,  2.20728274e-02, -2.27543190e-02,\n",
       "        7.67245144e-02,  6.20339736e-02,  6.26424924e-02, -1.98013280e-02,\n",
       "        6.63182884e-02, -1.61161162e-02, -6.13028817e-02,  1.23823017e-01,\n",
       "        4.40399833e-02, -4.74112034e-02,  8.61000828e-03, -1.80275701e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "builtin_function_or_method"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert data to milvus\n",
    "\n",
    "#data is in tupe,it has id,summaries and embeddings as separate lists in it\n",
    "\n",
    "def insert_data(collection, data):\n",
    "    ids, all_texts, embeddings = data\n",
    "    entities = [\n",
    "        ids,\n",
    "        all_texts,\n",
    "        embeddings\n",
    "    ]\n",
    "    collection.insert(entities)\n",
    "    collection.flush()\n",
    "\n",
    "insert_data(text_collection, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Techniques\n",
    "\n",
    "Objective:To create hybrid search.Hybrid search: Combining Sparse retriever with dense retriver\n",
    "\n",
    "- Creating Index\n",
    "- Creating vector store, and ccreating a retriever\n",
    "- Using ensemble retriever from langchain to retrieve which uses BM25 and the retriever made\n",
    "- Using a reranking algorithm \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_milvus\n",
      "  Downloading langchain_milvus-0.1.2-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.20 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from langchain_milvus) (0.2.20)\n",
      "Requirement already satisfied: pymilvus<3.0.0,>=2.4.3 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from langchain_milvus) (2.4.4)\n",
      "Requirement already satisfied: scipy<2.0,>=1.9 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from langchain_milvus) (1.14.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.20->langchain_milvus) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.20->langchain_milvus) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.20->langchain_milvus) (0.1.88)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.20->langchain_milvus) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.20->langchain_milvus) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.20->langchain_milvus) (8.5.0)\n",
      "Requirement already satisfied: setuptools>=67 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from pymilvus<3.0.0,>=2.4.3->langchain_milvus) (71.1.0)\n",
      "Requirement already satisfied: grpcio<=1.63.0,>=1.49.1 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from pymilvus<3.0.0,>=2.4.3->langchain_milvus) (1.63.0)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from pymilvus<3.0.0,>=2.4.3->langchain_milvus) (5.27.2)\n",
      "Requirement already satisfied: environs<=9.5.0 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from pymilvus<3.0.0,>=2.4.3->langchain_milvus) (9.5.0)\n",
      "Requirement already satisfied: ujson>=2.0.0 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from pymilvus<3.0.0,>=2.4.3->langchain_milvus) (5.10.0)\n",
      "Requirement already satisfied: pandas>=1.2.4 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from pymilvus<3.0.0,>=2.4.3->langchain_milvus) (2.2.2)\n",
      "Requirement already satisfied: numpy<2.3,>=1.23.5 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from scipy<2.0,>=1.9->langchain_milvus) (1.26.4)\n",
      "Requirement already satisfied: marshmallow>=3.0.0 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from environs<=9.5.0->pymilvus<3.0.0,>=2.4.3->langchain_milvus) (3.21.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from environs<=9.5.0->pymilvus<3.0.0,>=2.4.3->langchain_milvus) (1.0.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.20->langchain_milvus) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.20->langchain_milvus) (3.10.6)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.20->langchain_milvus) (2.32.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from pandas>=1.2.4->pymilvus<3.0.0,>=2.4.3->langchain_milvus) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from pandas>=1.2.4->pymilvus<3.0.0,>=2.4.3->langchain_milvus) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from pandas>=1.2.4->pymilvus<3.0.0,>=2.4.3->langchain_milvus) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3.0,>=0.2.20->langchain_milvus) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3.0,>=0.2.20->langchain_milvus) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3.0,>=0.2.20->langchain_milvus) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus<3.0.0,>=2.4.3->langchain_milvus) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.20->langchain_milvus) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.20->langchain_milvus) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.20->langchain_milvus) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.20->langchain_milvus) (2024.7.4)\n",
      "Downloading langchain_milvus-0.1.2-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: langchain_milvus\n",
      "Successfully installed langchain_milvus-0.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\All_projects\\Question_Answering_System\\qaenv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "embedding_milvus = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Index\n",
    "\n",
    "\n",
    "\n",
    "from langchain_milvus import Milvus\n",
    "\n",
    "vectorstore = Milvus.from_texts(  \n",
    "    texts=all_texts,\n",
    "    embedding= embedding_milvus,\n",
    "    connection_args={\n",
    "        \"uri\": \"http://localhost:19530\",\n",
    "    },\n",
    "    drop_old=False,  # Drop the old Milvus collection if it exists\n",
    ")\n",
    "\n",
    "# Convert the vector store to a retriever\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.vectorstores.base.VectorStoreRetriever"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rank_bm25\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: numpy in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from rank_bm25) (1.26.4)\n",
      "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Installing collected packages: rank_bm25\n",
      "Successfully installed rank_bm25-0.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_texts(\n",
    "    all_texts)\n",
    "bm25_retriever.k = 2  #parameter to change\n",
    "\n",
    "# initialize the ensemble retriever\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, retriever], weights=[0.5, 0.5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query initialisation\n",
    "\n",
    "query=\"What is catterpillar?\"\n",
    "\n",
    "doc_rel= ensemble_retriever.get_relevant_documents(query)\n",
    "\n",
    "doc_texts = [doc.page_content for doc in doc_rel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Reproducti on of this material is not covered under  authorization by any reproduction rights  \\norganization.\\n\\nTo order copies or request per mission to reproduce materials, contact Iv ey Publishing, Ivey Business School, West ern \\nUniversity, London, Ontario, Canada, N6G 0N1; (t) 519.661.3208; (e) cases@ivey.ca; www.iveycases.com.'),\n",
       " Document(metadata={'pk': 451316351972210688}, page_content='1 Vertex, “Caterpillar’s Stra tegy for World-Class Value Added Tax Management,” May 2012, \\nwww.vertexinc.com/ResourceCenter/WhitePapers/PDFs/vertex-vat-caterpillar-whi te-paper-dsb-review-v2.pdf, accessed May \\n8, 2013.\\n\\n2 Caterpillar, “Information Technol ogy,” www.caterpillar.com/cda/layout?m=629355&x=7&id=2492888, accessed May 8, \\n2013.\\n\\n3 Kim Laudrum, “Lovat Has Tunnel Vision,”  Plant, February 18, 2008: pp.\\n\\n17—19.2013.\\n\\n3 Kim Laudrum, “Lovat Has Tunnel Vision,”  Plant, February 18, 2008: pp.\\n\\n17—19.'),\n",
       " Document(page_content='Aside from an IT audit performed on CTCC’s computer network, there was no formal assessment \\nperformed on the company’s overall information mana gement needs to determine how the subsidiary \\nThis document is authorized for use only in Prof Kalpit Sharma©s MSDSM01_Computer and Information Systems at Indian Institute of Management - Amritsar from Dec 2023 to Jun 2024.'),\n",
       " Document(metadata={'pk': 451316351972210689}, page_content='This document is authorized for use only in Prof Kalpit Sharma©s MSDSM01_Computer and Information Systems at Indian Institute of Management - Amritsar from Dec 2023 to Jun 2024.Page 3 9B13E030  \\n \\n \\n In 2008, Caterpillar Inc. announced the entry into the tunnel boring business through the acquisition of \\nLovat Inc. At the time of acquisition, Caterpillar in tended to leverage its gl obal purchasing organization, \\nits global reach and its experience in large-scale manu facturing processes to support and invest in Lovat’s \\nproduct line and in the tunnel boring business.'),\n",
       " Document(metadata={'pk': 451316351972210685}, page_content='CATERPILLAR TUNNELING OVERVIEW \\n \\nFounded in 1972 as Lovat Inc., CTCC was a leadi ng tunneling technologies provider for soft ground to \\nhard rock geological conditions, specializing in th e custom design and manufacture of tunnel boring \\nmachines (TBMs) used in the cons truction of transportation and utility tunnels ranging from two to 12 \\nmetres in diameter.\\n\\nThe company also offered refurb ishments and reselling of TBMs, technical and field \\nservices support, product support and spare parts fulfillment.'),\n",
       " Document(metadata={'pk': 451316351972210708}, page_content='Caterpillar\\'s business intelligence (BI) platform was deployed as an intermediate solution to facilitate business decision making, but it became even more critical after the cancellation of the ERP system. The platform helped transform raw and disparate business data into actionable insights, but it faced challenges due to limited IT resources, an inflexible ERP infrastructure, and imbalanced user adoption.\\n\\nThe BI platform allowed users to link disparate data sources, but its adoption varied across business units, creating an imbalanced reporting landscape. This led to two types of users: \"analytics junkies\" who were tech-savvy and hands-on with data visualization utilities, and \"canned report users\" who were passive and preferred traditional channels.\\n\\nThe platform became both a go-to tool for effective decision making for some and a source of multiple versions of the truth for others. This created \"information insiders\" who were more proficient in extracting business insights than others. To fully utilize the BI platform, Jon McEwan, the business resource manager, had to focus on user needs and address the flaws of the initial implementation.')]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Reproducti on of this material is not covered under  authorization by any reproduction rights  \\norganization.\\n\\nTo order copies or request per mission to reproduce materials, contact Iv ey Publishing, Ivey Business School, West ern \\nUniversity, London, Ontario, Canada, N6G 0N1; (t) 519.661.3208; (e) cases@ivey.ca; www.iveycases.com.',\n",
       "  {}],\n",
       " ['1 Vertex, “Caterpillar’s Stra tegy for World-Class Value Added Tax Management,” May 2012, \\nwww.vertexinc.com/ResourceCenter/WhitePapers/PDFs/vertex-vat-caterpillar-whi te-paper-dsb-review-v2.pdf, accessed May \\n8, 2013.\\n\\n2 Caterpillar, “Information Technol ogy,” www.caterpillar.com/cda/layout?m=629355&x=7&id=2492888, accessed May 8, \\n2013.\\n\\n3 Kim Laudrum, “Lovat Has Tunnel Vision,”  Plant, February 18, 2008: pp.\\n\\n17—19.2013.\\n\\n3 Kim Laudrum, “Lovat Has Tunnel Vision,”  Plant, February 18, 2008: pp.\\n\\n17—19.',\n",
       "  {'pk': 451316351972210688}],\n",
       " ['Aside from an IT audit performed on CTCC’s computer network, there was no formal assessment \\nperformed on the company’s overall information mana gement needs to determine how the subsidiary \\nThis document is authorized for use only in Prof Kalpit Sharma©s MSDSM01_Computer and Information Systems at Indian Institute of Management - Amritsar from Dec 2023 to Jun 2024.',\n",
       "  {}],\n",
       " ['This document is authorized for use only in Prof Kalpit Sharma©s MSDSM01_Computer and Information Systems at Indian Institute of Management - Amritsar from Dec 2023 to Jun 2024.Page 3 9B13E030  \\n \\n \\n In 2008, Caterpillar Inc. announced the entry into the tunnel boring business through the acquisition of \\nLovat Inc. At the time of acquisition, Caterpillar in tended to leverage its gl obal purchasing organization, \\nits global reach and its experience in large-scale manu facturing processes to support and invest in Lovat’s \\nproduct line and in the tunnel boring business.',\n",
       "  {'pk': 451316351972210689}],\n",
       " ['CATERPILLAR TUNNELING OVERVIEW \\n \\nFounded in 1972 as Lovat Inc., CTCC was a leadi ng tunneling technologies provider for soft ground to \\nhard rock geological conditions, specializing in th e custom design and manufacture of tunnel boring \\nmachines (TBMs) used in the cons truction of transportation and utility tunnels ranging from two to 12 \\nmetres in diameter.\\n\\nThe company also offered refurb ishments and reselling of TBMs, technical and field \\nservices support, product support and spare parts fulfillment.',\n",
       "  {'pk': 451316351972210685}],\n",
       " ['Caterpillar\\'s business intelligence (BI) platform was deployed as an intermediate solution to facilitate business decision making, but it became even more critical after the cancellation of the ERP system. The platform helped transform raw and disparate business data into actionable insights, but it faced challenges due to limited IT resources, an inflexible ERP infrastructure, and imbalanced user adoption.\\n\\nThe BI platform allowed users to link disparate data sources, but its adoption varied across business units, creating an imbalanced reporting landscape. This led to two types of users: \"analytics junkies\" who were tech-savvy and hands-on with data visualization utilities, and \"canned report users\" who were passive and preferred traditional channels.\\n\\nThe platform became both a go-to tool for effective decision making for some and a source of multiple versions of the truth for others. This created \"information insiders\" who were more proficient in extracting business insights than others. To fully utilize the BI platform, Jon McEwan, the business resource manager, had to focus on user needs and address the flaws of the initial implementation.',\n",
       "  {'pk': 451316351972210708}]]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymilvus[model] in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (2.4.4)\n",
      "Requirement already satisfied: setuptools>=67 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from pymilvus[model]) (71.1.0)\n",
      "Requirement already satisfied: grpcio<=1.63.0,>=1.49.1 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from pymilvus[model]) (1.63.0)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from pymilvus[model]) (5.27.2)\n",
      "Requirement already satisfied: environs<=9.5.0 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from pymilvus[model]) (9.5.0)\n",
      "Requirement already satisfied: ujson>=2.0.0 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from pymilvus[model]) (5.10.0)\n",
      "Requirement already satisfied: pandas>=1.2.4 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from pymilvus[model]) (2.2.2)\n",
      "Collecting milvus-model>=0.1.0 (from pymilvus[model])\n",
      "  Downloading milvus_model-0.2.3-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: marshmallow>=3.0.0 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from environs<=9.5.0->pymilvus[model]) (3.21.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from environs<=9.5.0->pymilvus[model]) (1.0.1)\n",
      "Requirement already satisfied: transformers>=4.36.0 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from milvus-model>=0.1.0->pymilvus[model]) (4.42.4)\n",
      "Collecting onnxruntime (from milvus-model>=0.1.0->pymilvus[model])\n",
      "  Downloading onnxruntime-1.18.1-cp312-cp312-win_amd64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from milvus-model>=0.1.0->pymilvus[model]) (1.14.0)\n",
      "Requirement already satisfied: numpy in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from milvus-model>=0.1.0->pymilvus[model]) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from pandas>=1.2.4->pymilvus[model]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from pandas>=1.2.4->pymilvus[model]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from pandas>=1.2.4->pymilvus[model]) (2024.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from marshmallow>=3.0.0->environs<=9.5.0->pymilvus[model]) (24.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus[model]) (1.16.0)\n",
      "Requirement already satisfied: filelock in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (0.23.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (2024.5.15)\n",
      "Requirement already satisfied: requests in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (4.66.4)\n",
      "Collecting coloredlogs (from onnxruntime->milvus-model>=0.1.0->pymilvus[model])\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime->milvus-model>=0.1.0->pymilvus[model])\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Requirement already satisfied: sympy in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from onnxruntime->milvus-model>=0.1.0->pymilvus[model]) (1.13.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from tqdm>=4.27->transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (0.4.6)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->milvus-model>=0.1.0->pymilvus[model])\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from requests->transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from requests->transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from requests->transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from requests->transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\all_projects\\question_answering_system\\qaenv\\lib\\site-packages (from sympy->onnxruntime->milvus-model>=0.1.0->pymilvus[model]) (1.3.0)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime->milvus-model>=0.1.0->pymilvus[model])\n",
      "  Using cached pyreadline3-3.4.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Downloading milvus_model-0.2.3-py3-none-any.whl (29 kB)\n",
      "Downloading onnxruntime-1.18.1-cp312-cp312-win_amd64.whl (5.6 MB)\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.5/5.6 MB 14.9 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 1.6/5.6 MB 21.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.1/5.6 MB 28.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 3.5/5.6 MB 24.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.4/5.6 MB 28.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.6/5.6 MB 25.5 MB/s eta 0:00:00\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "Installing collected packages: pyreadline3, flatbuffers, humanfriendly, coloredlogs, onnxruntime, milvus-model\n",
      "Successfully installed coloredlogs-15.0.1 flatbuffers-24.3.25 humanfriendly-10.0 milvus-model-0.2.3 onnxruntime-1.18.1 pyreadline3-3.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pymilvus[model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Re-ranking algorithm cross encoder(open source)\n",
    "\n",
    "from pymilvus.model.reranker import CrossEncoderRerankFunction\n",
    "\n",
    "# Define the rerank function\n",
    "ce_rf = CrossEncoderRerankFunction(\n",
    "    model_name=\"cross-encoder/ms-marco-MiniLM-L-6-v2\",  # Specify the model name. Defaults to an emtpy string.\n",
    "    device=\"cpu\" # Specify the device to use, e.g., 'cpu' or 'cuda:0'\n",
    ")\n",
    "\n",
    "Re_ranked_docs= ce_rf(query,doc_texts)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "\n",
    "model = HuggingFaceCrossEncoder(model_name=\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "compressor = CrossEncoderReranker(model=model, top_n=3)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=ensemble_retriever\n",
    ")\n",
    "\n",
    "compressed_docs = compression_retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'pk': 451316351972210786}, page_content='Caterpillar\\'s business intelligence (BI) platform was deployed as an intermediate solution to facilitate business decision making, but it became even more critical after the cancellation of the ERP system. The platform helped transform raw and disparate business data into actionable insights, but it faced challenges due to limited IT resources, an inflexible ERP infrastructure, and imbalanced user adoption.\\n\\nThe BI platform allowed users to link disparate data sources, but its adoption varied across business units, creating an imbalanced reporting landscape. This led to two types of users: \"analytics junkies\" who were tech-savvy and hands-on with data visualization utilities, and \"canned report users\" who were passive and preferred traditional channels.\\n\\nThe platform became both a go-to tool for effective decision making for some and a source of multiple versions of the truth for others. This created \"information insiders\" who were more proficient in extracting business insights than others. To fully utilize the BI platform, Jon McEwan, the business resource manager, had to focus on user needs and address the flaws of the initial implementation.'),\n",
       " Document(metadata={'pk': 451316351972210763}, page_content='CATERPILLAR TUNNELING OVERVIEW \\n \\nFounded in 1972 as Lovat Inc., CTCC was a leadi ng tunneling technologies provider for soft ground to \\nhard rock geological conditions, specializing in th e custom design and manufacture of tunnel boring \\nmachines (TBMs) used in the cons truction of transportation and utility tunnels ranging from two to 12 \\nmetres in diameter.\\n\\nThe company also offered refurb ishments and reselling of TBMs, technical and field \\nservices support, product support and spare parts fulfillment.'),\n",
       " Document(metadata={'pk': 451316351972210766}, page_content='1 Vertex, “Caterpillar’s Stra tegy for World-Class Value Added Tax Management,” May 2012, \\nwww.vertexinc.com/ResourceCenter/WhitePapers/PDFs/vertex-vat-caterpillar-whi te-paper-dsb-review-v2.pdf, accessed May \\n8, 2013.\\n\\n2 Caterpillar, “Information Technol ogy,” www.caterpillar.com/cda/layout?m=629355&x=7&id=2492888, accessed May 8, \\n2013.\\n\\n3 Kim Laudrum, “Lovat Has Tunnel Vision,”  Plant, February 18, 2008: pp.\\n\\n17—19.2013.\\n\\n3 Kim Laudrum, “Lovat Has Tunnel Vision,”  Plant, February 18, 2008: pp.\\n\\n17—19.')]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RerankResult object: [RerankResult(text='Caterpillar\\'s business intelligence (BI) platform was deployed as an intermediate solution to facilitate business decision making, but it became even more critical after the cancellation of the ERP system. The platform helped transform raw and disparate business data into actionable insights, but it faced challenges due to limited IT resources, an inflexible ERP infrastructure, and imbalanced user adoption.\\n\\nThe BI platform allowed users to link disparate data sources, but its adoption varied across business units, creating an imbalanced reporting landscape. This led to two types of users: \"analytics junkies\" who were tech-savvy and hands-on with data visualization utilities, and \"canned report users\" who were passive and preferred traditional channels.\\n\\nThe platform became both a go-to tool for effective decision making for some and a source of multiple versions of the truth for others. This created \"information insiders\" who were more proficient in extracting business insights than others. To fully utilize the BI platform, Jon McEwan, the business resource manager, had to focus on user needs and address the flaws of the initial implementation.', score=-5.817600250244141, index=5), RerankResult(text='CATERPILLAR TUNNELING OVERVIEW \\n \\nFounded in 1972 as Lovat Inc., CTCC was a leadi ng tunneling technologies provider for soft ground to \\nhard rock geological conditions, specializing in th e custom design and manufacture of tunnel boring \\nmachines (TBMs) used in the cons truction of transportation and utility tunnels ranging from two to 12 \\nmetres in diameter.\\n\\nThe company also offered refurb ishments and reselling of TBMs, technical and field \\nservices support, product support and spare parts fulfillment.', score=-6.760643005371094, index=4), RerankResult(text='1 Vertex, “Caterpillar’s Stra tegy for World-Class Value Added Tax Management,” May 2012, \\nwww.vertexinc.com/ResourceCenter/WhitePapers/PDFs/vertex-vat-caterpillar-whi te-paper-dsb-review-v2.pdf, accessed May \\n8, 2013.\\n\\n2 Caterpillar, “Information Technol ogy,” www.caterpillar.com/cda/layout?m=629355&x=7&id=2492888, accessed May 8, \\n2013.\\n\\n3 Kim Laudrum, “Lovat Has Tunnel Vision,”  Plant, February 18, 2008: pp.\\n\\n17—19.2013.\\n\\n3 Kim Laudrum, “Lovat Has Tunnel Vision,”  Plant, February 18, 2008: pp.\\n\\n17—19.', score=-7.901247978210449, index=1), RerankResult(text='This document is authorized for use only in Prof Kalpit Sharma©s MSDSM01_Computer and Information Systems at Indian Institute of Management - Amritsar from Dec 2023 to Jun 2024.Page 3 9B13E030  \\n \\n \\n In 2008, Caterpillar Inc. announced the entry into the tunnel boring business through the acquisition of \\nLovat Inc. At the time of acquisition, Caterpillar in tended to leverage its gl obal purchasing organization, \\nits global reach and its experience in large-scale manu facturing processes to support and invest in Lovat’s \\nproduct line and in the tunnel boring business.', score=-7.976595878601074, index=3), RerankResult(text='Reproducti on of this material is not covered under  authorization by any reproduction rights  \\norganization.\\n\\nTo order copies or request per mission to reproduce materials, contact Iv ey Publishing, Ivey Business School, West ern \\nUniversity, London, Ontario, Canada, N6G 0N1; (t) 519.661.3208; (e) cases@ivey.ca; www.iveycases.com.', score=-11.409317970275879, index=0)]\n"
     ]
    }
   ],
   "source": [
    "print(f\"RerankResult object: {Re_ranked_docs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add__', '__class__', '__class_getitem__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n"
     ]
    }
   ],
   "source": [
    "print(dir(Re_ranked_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_context = \"\\n\".join([doc.text for doc in Re_ranked_docs]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_metadata = [doc.metadata for doc in doc_rel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{},\n",
       " {'pk': 451316351972210688},\n",
       " {},\n",
       " {'pk': 451316351972210689},\n",
       " {'pk': 451316351972210685},\n",
       " {'pk': 451316351972210708}]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RerankResult(text='Caterpillar\\'s business intelligence (BI) platform was deployed as an intermediate solution to facilitate business decision making, but it became even more critical after the cancellation of the ERP system. The platform helped transform raw and disparate business data into actionable insights, but it faced challenges due to limited IT resources, an inflexible ERP infrastructure, and imbalanced user adoption.\\n\\nThe BI platform allowed users to link disparate data sources, but its adoption varied across business units, creating an imbalanced reporting landscape. This led to two types of users: \"analytics junkies\" who were tech-savvy and hands-on with data visualization utilities, and \"canned report users\" who were passive and preferred traditional channels.\\n\\nThe platform became both a go-to tool for effective decision making for some and a source of multiple versions of the truth for others. This created \"information insiders\" who were more proficient in extracting business insights than others. To fully utilize the BI platform, Jon McEwan, the business resource manager, had to focus on user needs and address the flaws of the initial implementation.', score=-5.817600250244141, index=5),\n",
       " RerankResult(text='CATERPILLAR TUNNELING OVERVIEW \\n \\nFounded in 1972 as Lovat Inc., CTCC was a leadi ng tunneling technologies provider for soft ground to \\nhard rock geological conditions, specializing in th e custom design and manufacture of tunnel boring \\nmachines (TBMs) used in the cons truction of transportation and utility tunnels ranging from two to 12 \\nmetres in diameter.\\n\\nThe company also offered refurb ishments and reselling of TBMs, technical and field \\nservices support, product support and spare parts fulfillment.', score=-6.760643005371094, index=4),\n",
       " RerankResult(text='1 Vertex, “Caterpillar’s Stra tegy for World-Class Value Added Tax Management,” May 2012, \\nwww.vertexinc.com/ResourceCenter/WhitePapers/PDFs/vertex-vat-caterpillar-whi te-paper-dsb-review-v2.pdf, accessed May \\n8, 2013.\\n\\n2 Caterpillar, “Information Technol ogy,” www.caterpillar.com/cda/layout?m=629355&x=7&id=2492888, accessed May 8, \\n2013.\\n\\n3 Kim Laudrum, “Lovat Has Tunnel Vision,”  Plant, February 18, 2008: pp.\\n\\n17—19.2013.\\n\\n3 Kim Laudrum, “Lovat Has Tunnel Vision,”  Plant, February 18, 2008: pp.\\n\\n17—19.', score=-7.901247978210449, index=1),\n",
       " RerankResult(text='This document is authorized for use only in Prof Kalpit Sharma©s MSDSM01_Computer and Information Systems at Indian Institute of Management - Amritsar from Dec 2023 to Jun 2024.Page 3 9B13E030  \\n \\n \\n In 2008, Caterpillar Inc. announced the entry into the tunnel boring business through the acquisition of \\nLovat Inc. At the time of acquisition, Caterpillar in tended to leverage its gl obal purchasing organization, \\nits global reach and its experience in large-scale manu facturing processes to support and invest in Lovat’s \\nproduct line and in the tunnel boring business.', score=-7.976595878601074, index=3),\n",
       " RerankResult(text='Reproducti on of this material is not covered under  authorization by any reproduction rights  \\norganization.\\n\\nTo order copies or request per mission to reproduce materials, contact Iv ey Publishing, Ivey Business School, West ern \\nUniversity, London, Ontario, Canada, N6G 0N1; (t) 519.661.3208; (e) cases@ivey.ca; www.iveycases.com.', score=-11.409317970275879, index=0)]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Re_ranked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_context(Re_ranked_docs):\n",
    "    # Extract text from each RerankResult object\n",
    "    context = \"\\n\".join([doc.text for doc in Re_ranked_docs])  # Accessing the 'text' attribute\n",
    "    return context\n",
    "my_context = prepare_context(Re_ranked_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is catterpillar?',\n",
       " 'result': \"Based on the provided context, Caterpillar appears to be a company that owns a subsidiary called Caterpillar Tunneling (CTCC), which is a leading provider of tunneling technologies and manufacturer of tunnel boring machines (TBMs). However, it's likely that Caterpillar is a larger company with a broader scope beyond tunneling technologies. Unfortunately, the provided context does not give a more detailed description of Caterpillar's overall business or operations.\"}"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chain invoke\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "template=\"\"\"\n",
    "You are an AI Assistant that can give answer for any query asked based on the documents provided to answer.\n",
    "Please be truthful and give direct answers. Please tell 'I don't know' if user query is not in CONTEXT\n",
    "\\n Question: {query}\n",
    "Context: {context}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt= ChatPromptTemplate.from_template(template)\n",
    "output_parser= StrOutputParser()\n",
    "\n",
    "chain= RetrievalQA.from_chain_type(llm=model_llm,retriever=compression_retriever)\n",
    "\n",
    "query=\"What is catterpillar?\"\n",
    "response= chain.invoke(query)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
